{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data 620, Project 3\n",
    "July 10, 2019 \n",
    "Team 6: Alice Friedman, Scott Jones, Jeff Littlejohn, and Jun Pan\n",
    "\n",
    "## Assignment Description\n",
    "Using any of the three classifiers described in chapter 6 of Natural Language Processing with Python, and any features you can think of, build the best name gender classifier you can. Begin by splitting the Names Corpus into three subsets: 500 words for the test set, 500 words for the devtest set, and the remaining 6900 words for the training set. Then, starting with the example name gender classifier, make incremental improvements. Use the dev-test set to check your progress. Once you are satisfied with your classifier, check its final performance on the test set. How does the performance on the test set compare to the performance on the dev-test set? Is this what you'd expect?\n",
    "\n",
    "Source: Natural Language Processing with Python, exercise 6.10.2.\n",
    "\n",
    "### Text Classification: Identifying Gender from the ```NLTK``` Names Corpus  \n",
    "\n",
    "Adapted from:\n",
    "\n",
    "- [GitHub, Vinovator](https://gist.github.com/vinovator/6e5bf1e1bc61687a1e809780c30d6bf6)\n",
    "\n",
    "- [Geeks for Geeks: Python Gender Identification by Name](https://www.geeksforgeeks.org/python-gender-identification-by-name-using-nltk/)\n",
    "\n",
    "\n",
    "First, we import the names corpus from the ```nltk``` list of corpuses, and create three sets of names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import names\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Mark', 'male'), ('Bjorn', 'male'), ('Stephan', 'male'), ('Hyatt', 'male'), ('Romain', 'male')] 2943\n",
      "[('Sheilah', 'female'), ('Carolyne', 'female'), ('Devondra', 'female'), ('Tessi', 'female'), ('Jean', 'female')] 5001\n",
      "[('Vikky', 'female'), ('Tamera', 'female'), ('Melisande', 'female'), ('Markus', 'male'), ('Petunia', 'female')] 7944\n"
     ]
    }
   ],
   "source": [
    "mcorpus = [(name, \"male\") for name in names.words(\"male.txt\")]\n",
    "fcorpus = [(name, \"female\") for name in names.words(\"female.txt\")]\n",
    "random.shuffle(mcorpus); random.shuffle(fcorpus)\n",
    "print(mcorpus[0:5],len(mcorpus))\n",
    "print(fcorpus[0:5],len(fcorpus))\n",
    "\n",
    "corpus = mcorpus + fcorpus\n",
    "random.shuffle(corpus)\n",
    "print(corpus[:5], len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's examine the data to see if we can determine any patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will subdivide the shuffled names corpus as follows:\n",
    "- A training set, used to train the model based on our selected features\n",
    "\n",
    "- A a development test (dev-test) set, which we will use to test progress on the gender identifier and perform error analysis\n",
    "\n",
    "- A final \"test\" set, which we will use to test how well our predictions ultimately worked\n",
    "\n",
    "In order to avoid overfitting the data, we will remix the training and dev-test with each new feature extraaction model. To prevent a lot of re-coding, we can write a function to remix the development-training corpus, after setting aside the first 500 male and female names as the final test slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to return a new training and dev-test mix of the corpus for each iteration of the model\n",
    "def reslicer(corpus):\n",
    "    \n",
    "    #prints message to explain output\n",
    "    print(\"Reslicer returns 3 sliced, remixed set of corpuses:\")\n",
    "    print(\"\\tThe first returned value is the remixed training corpus, length is variable\")\n",
    "    print(\"\\tThe second returned value is the remixed dev-test corpus, length is 500\")\n",
    "    print(\"\\tThe third returned value is the un-remixed test set, length is 500\\n\")\n",
    "    \n",
    "    final_test_n = 500 # per assignment instructions\n",
    "    dev_test_n = 500 # per assignment instructions\n",
    "    \n",
    "    #reserve first 500 for the final test    \n",
    "    test_corpus = corpus[:final_test_n] \n",
    "    \n",
    "    #create a copy of the dev_set to preserve the original test set before shuffling\n",
    "    dev_set = corpus[final_test_n:] \n",
    "    random.shuffle(dev_set) #remix before re-slicing\n",
    "    \n",
    "    #re-cut re-shuffled development set into dev-test set (len 500) and training set (remainder)\n",
    "    dev_test_corpus = dev_set[:dev_test_n]\n",
    "    train_corpus = dev_set[dev_test_n:]\n",
    "    \n",
    "    #prints sample of sets\n",
    "    print(\"Training Corpus Sample: \",train_corpus[0:3], \", Length: \", len(train_corpus)) #should be longer\n",
    "    print(\"Dev-Test Corpus Sample: \",dev_test_corpus[0:3], \", Length: \", len(dev_test_corpus)) #should have length 500\n",
    "    print(\"Test Corpus Sample: \", test_corpus[0:3], \", Length: \", len(test_corpus))\n",
    "    \n",
    "    return train_corpus, dev_test_corpus, test_corpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the above function, we can split the names corpus into a training set, dev-test set, and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reslicer returns 3 sliced, remixed set of corpuses:\n",
      "\tThe first returned value is the remixed training corpus, length is variable\n",
      "\tThe second returned value is the remixed dev-test corpus, length is 500\n",
      "\tThe third returned value is the un-remixed test set, length is 500\n",
      "\n",
      "Training Corpus Sample:  [('Roxanne', 'female'), ('Charmane', 'female'), ('Teddy', 'female')] , Length:  6944\n",
      "Dev-Test Corpus Sample:  [('Vikki', 'female'), ('Jerold', 'male'), ('Tomi', 'female')] , Length:  500\n",
      "Test Corpus Sample:  [('Vikky', 'female'), ('Tamera', 'female'), ('Melisande', 'female')] , Length:  500\n"
     ]
    }
   ],
   "source": [
    "train_names, dev_names, test_names = reslicer(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-running the code will remix the training and dev-test sets, while leaving the original test names intact, allowing us to quickly run new models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reslicer returns 3 sliced, remixed set of corpuses:\n",
      "\tThe first returned value is the remixed training corpus, length is variable\n",
      "\tThe second returned value is the remixed dev-test corpus, length is 500\n",
      "\tThe third returned value is the un-remixed test set, length is 500\n",
      "\n",
      "Training Corpus Sample:  [('Gerhardine', 'female'), ('Broddy', 'male'), ('Vale', 'female')] , Length:  6944\n",
      "Dev-Test Corpus Sample:  [('Kiri', 'female'), ('Manda', 'female'), ('Tedda', 'female')] , Length:  500\n",
      "Test Corpus Sample:  [('Vikky', 'female'), ('Tamera', 'female'), ('Melisande', 'female')] , Length:  500\n"
     ]
    }
   ],
   "source": [
    "train_names, dev_names, test_names = reslicer(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding, let's take a look at the labeled data. To avoid fixing the results, we will only look at the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N', 'No', 'Noa', 'Noah', 'o', 'oa', 'oah', 'a', 'ah', 'h']\n"
     ]
    }
   ],
   "source": [
    "def name_parts(name):\n",
    "    i = 0\n",
    "    letters = ''\n",
    "    parts = []\n",
    "    ans = ''\n",
    "    for letter in name:\n",
    "        next_part = name[i:]\n",
    "        for letter in next_part:\n",
    "            letters += letter\n",
    "            parts.append(letters)\n",
    "            i+=0\n",
    "        letters=''\n",
    "        i += 1\n",
    "    return parts\n",
    "print(name_parts(\"Noah\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_dict = {'label':[], 'feature':[], 'name':[]}\n",
    "\n",
    "for name, label in train_names:\n",
    "    parts = name_parts(name)\n",
    "    for part in parts:\n",
    "        name_dict['label'].append(label)\n",
    "        name_dict['feature'].append(part)\n",
    "        name_dict['name'].append(name)\n",
    "\n",
    "data = pd.DataFrame(name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature  label \n",
       "a        female    3583\n",
       "e        female    3415\n",
       "i        female    2567\n",
       "n        female    2308\n",
       "l        female    2026\n",
       "r        female    1757\n",
       "e        male      1609\n",
       "a        male      1274\n",
       "r        male      1237\n",
       "n        male      1073\n",
       "i        male      1049\n",
       "t        female    1021\n",
       "o        female     946\n",
       "         male       925\n",
       "l        male       873\n",
       "y        female     796\n",
       "s        female     775\n",
       "d        female     616\n",
       "t        male       572\n",
       "h        female     557\n",
       "Name: feature, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = data.groupby(['feature', 'label'])['feature'].count()\n",
    "counts = counts.sort_values(ascending = False)\n",
    "counts.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've taken a look at the data, we can start to work on developing a model.\n",
    "\n",
    "First, we can combine the ```reslicer``` function with a feature extracter function, ```feature_ext```, to generate labeled data with features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to avoid overfitting the data, we will remix the training and dev-test with each new feature extraaction model. To prevent a lot of re-coding, we can write a function to remix the development-training corpus, after setting aside the first 500 male and female names as the final test slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to process the names through feature extractor\n",
    "def feature_ext(feature_func, corpus):\n",
    "    \n",
    "    #first, remix and reslice the data to ensure we are using a new mix of dev-test and training data each time\n",
    "    train_names, dev_names, test_names = reslicer(corpus)\n",
    "    \n",
    "    #then, extract features from the names slices\n",
    "    train_set = [(feature_func(n), gender) for (n, gender) in train_names]\n",
    "    devtest_set = [(feature_func(n), gender) for (n, gender) in dev_names]\n",
    "\n",
    "    \n",
    "    return train_set, devtest_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, a ```test_model``` function will combine all of the above to provide feedback on the feature extraction method selected to develop a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def test_model(feature_func, corpus):\n",
    "    \n",
    "    # Run the feature_ext function to create the necessary labeled feature sets\n",
    "    train_set, devtest_set = feature_ext(feature_func, corpus)\n",
    "    \n",
    "    # Train on the training set using the naiveBayes classifier built in to nltk\n",
    "    classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "    # Test the accuracy of the classifier on the dev data--this is so we can evaluate errors and make tweaks\n",
    "    a = round(nltk.classify.accuracy(classifier, devtest_set), 4)*100\n",
    "    \n",
    "    # Format results as a 2 digit decimal\n",
    "    accuracy = f'{a:.2f}'\n",
    "    \n",
    "    # Print message with results\n",
    "    print(\"\\n\")\n",
    "    print(\"Model is %s percent accurate\" % accuracy)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # Examine classifier to determine which last letter is most effective for predicting gender\n",
    "    print(classifier.show_most_informative_features(10))\n",
    "    \n",
    "    # Function to find errors\n",
    "    def find_errors(dev_names, feature_func):\n",
    "    \n",
    "        errors = {'name' : [], 'label' : [], 'guess' : [], 'features': [] }\n",
    "        \n",
    "        for (name, label) in dev_names:\n",
    "            guess = classifier.classify(feature_func(name))\n",
    "            features = feature_func(name)\n",
    "            if guess != label:\n",
    "                errors['name'].append(name)\n",
    "                errors['label'].append(label)\n",
    "                errors['guess'].append(guess)\n",
    "                errors['features'].append(features)\n",
    "        \n",
    "        errors = pd.DataFrame(errors)\n",
    "        \n",
    "        # Prints sample of errors\n",
    "        print(\"\\nErrors\")\n",
    "        print(errors.sample(20))\n",
    "    \n",
    "    # Runs errors function\n",
    "    errors = find_errors(dev_names, feature_func)\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on the last letter of the name\n",
    "\n",
    "Now that we have our functions set up, we can use them to test different feature extraction functions, starting with the last letter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_letter(name): #first feature extraction function to test\n",
    "    \n",
    "    return {\"last_letter\": name[-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reslicer returns 3 sliced, remixed set of corpuses:\n",
      "\tThe first returned value is the remixed training corpus, length is variable\n",
      "\tThe second returned value is the remixed dev-test corpus, length is 500\n",
      "\tThe third returned value is the un-remixed test set, length is 500\n",
      "\n",
      "Training Corpus Sample:  [('Bob', 'male'), ('Alex', 'male'), ('Clemmy', 'female')] , Length:  6944\n",
      "Dev-Test Corpus Sample:  [('Charlotta', 'female'), ('Sibyl', 'female'), ('Will', 'male')] , Length:  500\n",
      "Test Corpus Sample:  [('Vikky', 'female'), ('Tamera', 'female'), ('Melisande', 'female')] , Length:  500\n",
      "\n",
      "\n",
      "Model is 75.40 percent accurate\n",
      "\n",
      "\n",
      "Most Informative Features\n",
      "             last_letter = 'a'            female : male   =     33.9 : 1.0\n",
      "             last_letter = 'k'              male : female =     29.3 : 1.0\n",
      "             last_letter = 'f'              male : female =     13.4 : 1.0\n",
      "             last_letter = 'p'              male : female =     11.4 : 1.0\n",
      "             last_letter = 'v'              male : female =     10.0 : 1.0\n",
      "             last_letter = 'd'              male : female =      9.0 : 1.0\n",
      "             last_letter = 'o'              male : female =      8.4 : 1.0\n",
      "             last_letter = 'm'              male : female =      7.8 : 1.0\n",
      "             last_letter = 'r'              male : female =      7.8 : 1.0\n",
      "             last_letter = 'w'              male : female =      5.5 : 1.0\n",
      "None\n",
      "\n",
      "Errors\n",
      "          name   label   guess              features\n",
      "7          Del  female    male  {'last_letter': 'l'}\n",
      "70      Tonnie    male  female  {'last_letter': 'e'}\n",
      "94         Ely    male  female  {'last_letter': 'y'}\n",
      "11        Ajay    male  female  {'last_letter': 'y'}\n",
      "81        Seth    male  female  {'last_letter': 'h'}\n",
      "103  Westleigh    male  female  {'last_letter': 'h'}\n",
      "43       Bobby    male  female  {'last_letter': 'y'}\n",
      "2       Dannie    male  female  {'last_letter': 'e'}\n",
      "79        Ines  female    male  {'last_letter': 's'}\n",
      "104     Meghan  female    male  {'last_letter': 'n'}\n",
      "15       Joell  female    male  {'last_letter': 'l'}\n",
      "18    Kingsley    male  female  {'last_letter': 'y'}\n",
      "42         Cat  female    male  {'last_letter': 't'}\n",
      "45     Murdoch    male  female  {'last_letter': 'h'}\n",
      "51      Violet  female    male  {'last_letter': 't'}\n",
      "82    Adriaens  female    male  {'last_letter': 's'}\n",
      "23       Ronny    male  female  {'last_letter': 'y'}\n",
      "31    Terri-Jo  female    male  {'last_letter': 'o'}\n",
      "86       Ninon  female    male  {'last_letter': 'n'}\n",
      "17    Josselyn  female    male  {'last_letter': 'n'}\n"
     ]
    }
   ],
   "source": [
    "last_letter_model = test_model(last_letter, corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are interesting results! \n",
    "\n",
    "Does this basic model work for our names? Using the output from our model, we can try. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Alice. Guess:  female\n",
      "Name: Jun. Guess:  male\n",
      "Name: Scott. Guess:  male\n",
      "Name: Jeff. Guess:  male\n"
     ]
    }
   ],
   "source": [
    "team6names = ['Alice', 'Jun', 'Scott', 'Jeff']\n",
    "for name in team6names:\n",
    "    print (\"Name: \"+name+\". Guess: \", last_letter_model.classify(last_letter(name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works! Let's see if we can do any better by adding an additional feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on the last 3 letters of the name + last letter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we try adding the last 3 letters as well as just the last letter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reslicer returns 3 sliced, remixed set of corpuses:\n",
      "\tThe first returned value is the remixed training corpus, length is variable\n",
      "\tThe second returned value is the remixed dev-test corpus, length is 500\n",
      "\tThe third returned value is the un-remixed test set, length is 500\n",
      "\n",
      "Training Corpus Sample:  [('Rudy', 'male'), ('Will', 'male'), ('Jewell', 'female')] , Length:  6944\n",
      "Dev-Test Corpus Sample:  [('Tony', 'female'), ('Elita', 'female'), ('Darya', 'female')] , Length:  500\n",
      "Test Corpus Sample:  [('Vikky', 'female'), ('Tamera', 'female'), ('Melisande', 'female')] , Length:  500\n",
      "\n",
      "\n",
      "Model is 78.40 percent accurate\n",
      "\n",
      "\n",
      "Most Informative Features\n",
      "             last_letter = 'a'            female : male   =     33.9 : 1.0\n",
      "             last_letter = 'k'              male : female =     30.3 : 1.0\n",
      "            last3letters = 'ita'          female : male   =     24.9 : 1.0\n",
      "            last3letters = 'ana'          female : male   =     24.9 : 1.0\n",
      "            last3letters = 'tta'          female : male   =     21.5 : 1.0\n",
      "            last3letters = 'ard'            male : female =     19.0 : 1.0\n",
      "            last3letters = 'nne'          female : male   =     18.3 : 1.0\n",
      "             last_letter = 'v'              male : female =     15.5 : 1.0\n",
      "             last_letter = 'f'              male : female =     15.5 : 1.0\n",
      "            last3letters = 'old'            male : female =     15.1 : 1.0\n",
      "None\n",
      "\n",
      "Errors\n",
      "         name   label   guess                                     features\n",
      "30     Shayne    male  female  {'last_letter': 'e', 'last3letters': 'yne'}\n",
      "51       Ines  female    male  {'last_letter': 's', 'last3letters': 'nes'}\n",
      "15       Fred  female    male  {'last_letter': 'd', 'last3letters': 'red'}\n",
      "18        Dew  female    male  {'last_letter': 'w', 'last3letters': 'Dew'}\n",
      "25      Rocky    male  female  {'last_letter': 'y', 'last3letters': 'cky'}\n",
      "36      Suzzy  female    male  {'last_letter': 'y', 'last3letters': 'zzy'}\n",
      "44   Rutledge    male  female  {'last_letter': 'e', 'last3letters': 'dge'}\n",
      "14   Wallache    male  female  {'last_letter': 'e', 'last3letters': 'che'}\n",
      "55   Adriaens  female    male  {'last_letter': 's', 'last3letters': 'ens'}\n",
      "32   Gretchen  female    male  {'last_letter': 'n', 'last3letters': 'hen'}\n",
      "28   Blakeley  female    male  {'last_letter': 'y', 'last3letters': 'ley'}\n",
      "71      Marlo  female    male  {'last_letter': 'o', 'last3letters': 'rlo'}\n",
      "33      Ester  female    male  {'last_letter': 'r', 'last3letters': 'ter'}\n",
      "42     Tonnie    male  female  {'last_letter': 'e', 'last3letters': 'nie'}\n",
      "46     Mischa    male  female  {'last_letter': 'a', 'last3letters': 'cha'}\n",
      "48     Hamlen    male  female  {'last_letter': 'n', 'last3letters': 'len'}\n",
      "1       Maddy  female    male  {'last_letter': 'y', 'last3letters': 'ddy'}\n",
      "27     Violet  female    male  {'last_letter': 't', 'last3letters': 'let'}\n",
      "62   Florance  female    male  {'last_letter': 'e', 'last3letters': 'nce'}\n",
      "69  Agamemnon    male  female  {'last_letter': 'n', 'last3letters': 'non'}\n"
     ]
    }
   ],
   "source": [
    "def two_features(name):\n",
    "    return {\"last_letter\": name[-1], \"last3letters\": name[-3:]}  # feature set\n",
    "\n",
    "#note, we are automatically re-slicing the training/dev-test slices\n",
    "two_features_classifier = test_model(two_features, corpus) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the last three letters increased our accuracy by about 5 percentage points! Let's see if we can learn anything from the remaining errors to improve our model further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three features\n",
    "   \n",
    "If two features are better than one, will three be even better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reslicer returns 3 sliced, remixed set of corpuses:\n",
      "\tThe first returned value is the remixed training corpus, length is variable\n",
      "\tThe second returned value is the remixed dev-test corpus, length is 500\n",
      "\tThe third returned value is the un-remixed test set, length is 500\n",
      "\n",
      "Training Corpus Sample:  [('Aurel', 'female'), ('Geri', 'female'), ('Calida', 'female')] , Length:  6944\n",
      "Dev-Test Corpus Sample:  [('Marleen', 'female'), ('Donnie', 'male'), ('Maxwell', 'male')] , Length:  500\n",
      "Test Corpus Sample:  [('Vikky', 'female'), ('Tamera', 'female'), ('Melisande', 'female')] , Length:  500\n",
      "\n",
      "\n",
      "Model is 82.20 percent accurate\n",
      "\n",
      "\n",
      "Most Informative Features\n",
      "             last_letter = 'a'            female : male   =     32.4 : 1.0\n",
      "             last_letter = 'k'              male : female =     30.3 : 1.0\n",
      "            last3letters = 'ana'          female : male   =     24.4 : 1.0\n",
      "            last3letters = 'tta'          female : male   =     20.6 : 1.0\n",
      "            last3letters = 'ard'            male : female =     19.0 : 1.0\n",
      "            last3letters = 'nne'          female : male   =     19.0 : 1.0\n",
      "            last3letters = 'old'            male : female =     16.2 : 1.0\n",
      "            last3letters = 'son'            male : female =     15.9 : 1.0\n",
      "             last_letter = 'f'              male : female =     15.5 : 1.0\n",
      "            last3letters = 'vin'            male : female =     15.2 : 1.0\n",
      "None\n",
      "\n",
      "Errors\n",
      "        name   label   guess  \\\n",
      "9      Joell  female    male   \n",
      "13     Solly    male  female   \n",
      "25    Violet  female    male   \n",
      "5        Del  female    male   \n",
      "64      Mace    male  female   \n",
      "63     Denny    male  female   \n",
      "36      Dido  female    male   \n",
      "27     Keith    male  female   \n",
      "12     Hazel  female    male   \n",
      "19   Siobhan  female    male   \n",
      "62     Maris  female    male   \n",
      "26  Blakeley  female    male   \n",
      "10     Sammy  female    male   \n",
      "39     Clare    male  female   \n",
      "15      Fred  female    male   \n",
      "47      Ines  female    male   \n",
      "41    Tonnie    male  female   \n",
      "24  Herculie    male  female   \n",
      "35    Leanor  female    male   \n",
      "1     Dannie    male  female   \n",
      "\n",
      "                                             features  \n",
      "9   {'last_letter': 'l', 'last3letters': 'ell', 'f...  \n",
      "13  {'last_letter': 'y', 'last3letters': 'lly', 'f...  \n",
      "25  {'last_letter': 't', 'last3letters': 'let', 'f...  \n",
      "5   {'last_letter': 'l', 'last3letters': 'Del', 'f...  \n",
      "64  {'last_letter': 'e', 'last3letters': 'ace', 'f...  \n",
      "63  {'last_letter': 'y', 'last3letters': 'nny', 'f...  \n",
      "36  {'last_letter': 'o', 'last3letters': 'ido', 'f...  \n",
      "27  {'last_letter': 'h', 'last3letters': 'ith', 'f...  \n",
      "12  {'last_letter': 'l', 'last3letters': 'zel', 'f...  \n",
      "19  {'last_letter': 'n', 'last3letters': 'han', 'f...  \n",
      "62  {'last_letter': 's', 'last3letters': 'ris', 'f...  \n",
      "26  {'last_letter': 'y', 'last3letters': 'ley', 'f...  \n",
      "10  {'last_letter': 'y', 'last3letters': 'mmy', 'f...  \n",
      "39  {'last_letter': 'e', 'last3letters': 'are', 'f...  \n",
      "15  {'last_letter': 'd', 'last3letters': 'red', 'f...  \n",
      "47  {'last_letter': 's', 'last3letters': 'nes', 'f...  \n",
      "41  {'last_letter': 'e', 'last3letters': 'nie', 'f...  \n",
      "24  {'last_letter': 'e', 'last3letters': 'lie', 'f...  \n",
      "35  {'last_letter': 'r', 'last3letters': 'nor', 'f...  \n",
      "1   {'last_letter': 'e', 'last3letters': 'nie', 'f...  \n"
     ]
    }
   ],
   "source": [
    "def three_features(name):\n",
    "    return {\"last_letter\": name[-1], \"last3letters\": name[-3:], \"first_letter\": name[0]}  # feature set\n",
    "\n",
    "#note, we are automatically re-slicing the training/dev-test slices\n",
    "three_features_classifier = test_model(three_features, corpus) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, this didn't make a difference at all! Looks like the ```two_features_model``` is the winner. We can now test our best model on the test data--which has so far not been used to train any of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model on unused data\n",
    "\n",
    "The final step is to use the classify the ```test_set``` using ```two_features_model``` to see how we did. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Model is 82.00 percent accurate when used on the the test set\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def final_test(classifier, feature_func, name_set):\n",
    "    \n",
    "    #generate test_set\n",
    "    test_set = [(feature_func(n), gender) for (n, gender) in name_set]\n",
    "        \n",
    "    \n",
    "    #test the accuracy of the model on the test set\n",
    "    a = round(nltk.classify.accuracy(classifier, test_set), 4)*100\n",
    "    \n",
    "    #format and print output\n",
    "    accuracy = f'{a:.2f}'\n",
    "    print(\"\\n\")\n",
    "    print(\"Model is %s percent accurate when used on the the test set\" % accuracy)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "\n",
    "final_test(two_features_classifier, two_features, test_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK Summary\n",
    "In conclusion, the final test does not produce identical results when run on the test set (or even re-run on the a remixed development set). This should not be surprising because the model is making a prediction based on patterns that are not necessarily hard and fast rules. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `sklearn`  \n",
    "\n",
    "From the site: https://blog.ayoungprogrammer.com/2016/04/determining-gender-of-name-with-80.html/    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the names corpus with gender assignment; each name is converted to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_names = ([(name.lower(), \"M\") for name in names.words(\"male.txt\")] +\n",
    "                 [(name.lower(), \"F\") for name in names.words(\"female.txt\")])\n",
    "\n",
    "my_data = np.asarray(labeled_names) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `sklearn`, we train a model on numbers associated with each letter in the name, where a=1, b=2, c=3, ... in this manner a model is created based on integer values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7219679633867276\n",
      "0.7292143401983219\n",
      "0.7315026697177727\n",
      "0.7257818459191457\n",
      "0.7265446224256293\n"
     ]
    }
   ],
   "source": [
    "def name_count(name):\n",
    "    arr = np.zeros(65)\n",
    "    for ind, x in enumerate(name):\n",
    "        arr[ord(x)-ord('a')] += 1\n",
    "    return arr\n",
    "\n",
    "name_map = np.vectorize(name_count, otypes=[np.ndarray])\n",
    "Xlist = name_map(np.asarray(list(zip(*my_data))[0],dtype=str))\n",
    "X = np.array(Xlist.tolist())\n",
    "y = [x[1] for x in my_data]\n",
    "\n",
    "for x in range(5):\n",
    "    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.33)\n",
    "    clf = RandomForestClassifier(n_estimators=100, min_samples_split=2)\n",
    "    clf.fit(Xtr, ytr)\n",
    "    print(np.mean(clf.predict(Xte) == yte))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7829900839054157\n",
      "0.7807017543859649\n",
      "0.7864225781845919\n",
      "0.7688787185354691\n",
      "0.7936689549961862\n"
     ]
    }
   ],
   "source": [
    "def name_count2(name):\n",
    "    arr = np.zeros(65+26)\n",
    "    for ind, x in enumerate(name):\n",
    "        arr[ord(x)-ord('a')] += 1\n",
    "        arr[ord(x)-ord('a')+26] += ind+1\n",
    "    return arr\n",
    "\n",
    "name_map2 = np.vectorize(name_count2, otypes=[np.ndarray])\n",
    "Xlist = name_map2(np.asarray(list(zip(*my_data))[0],dtype=str))\n",
    "X = np.array(Xlist.tolist())\n",
    "y = [x[1] for x in my_data]\n",
    "\n",
    "for x in range(5):\n",
    "    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.33)\n",
    "    clf = RandomForestClassifier(n_estimators=100, min_samples_split=2)\n",
    "    clf.fit(Xtr, ytr)\n",
    "    print(np.mean(clf.predict(Xte) == yte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7963386727688787\n",
      "0.7967200610221206\n",
      "0.7894736842105263\n",
      "0.7917620137299771\n",
      "0.7921434019832189\n"
     ]
    }
   ],
   "source": [
    "def name_count3(name):\n",
    "    arr = np.zeros(1800)\n",
    "    # Iterate each character\n",
    "    for ind, x in enumerate(name):\n",
    "        arr[ord(x)-ord('a')] += 1\n",
    "        arr[ord(x)-ord('a')+26] += ind+1\n",
    "    # Iterate every 2 characters\n",
    "    for x in range(len(name)-1):\n",
    "        ind = (ord(name[x])-ord('a'))*26 + (ord(name[x+1])-ord('a')) + 52\n",
    "        arr[ind] += 1\n",
    "    return arr\n",
    "\n",
    "name_map3 = np.vectorize(name_count3, otypes=[np.ndarray])\n",
    "Xlist = name_map3(np.asarray(list(zip(*my_data))[0],dtype=str))\n",
    "X = np.array(Xlist.tolist())\n",
    "y = [x[1] for x in my_data]\n",
    "\n",
    "for x in range(5):\n",
    "    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.33)\n",
    "    clf = RandomForestClassifier(n_estimators=100, min_samples_split=2)\n",
    "    clf.fit(Xtr, ytr)\n",
    "    print(np.mean(clf.predict(Xte) == yte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8180778032036613\n",
      "0.8188405797101449\n",
      "0.8096872616323417\n",
      "0.8032036613272311\n",
      "0.8081617086193745\n"
     ]
    }
   ],
   "source": [
    "def name_count4(name):\n",
    "    arr = np.zeros(1800)\n",
    "    # Iterate each character\n",
    "    for ind, x in enumerate(name):\n",
    "        arr[ord(x)-ord('a')] += 1\n",
    "        arr[ord(x)-ord('a')+26] += ind+1\n",
    "    # Iterate every 2 characters\n",
    "    for x in range(len(name)-1):\n",
    "        ind = (ord(name[x])-ord('a'))*26 + (ord(name[x+1])-ord('a')) + 52\n",
    "        arr[ind] += 1\n",
    "    # Last character\n",
    "    arr[-3] = ord(name[-1])-ord('a')+1\n",
    "    # Second Last character\n",
    "    arr[-2] = ord(name[-2])-ord('a')+1\n",
    "    # Length of name\n",
    "    arr[-1] = len(name)\n",
    "    return arr\n",
    "\n",
    "name_map4 = np.vectorize(name_count4, otypes=[np.ndarray])\n",
    "Xlist = name_map4(np.asarray(list(zip(*my_data))[0],dtype=str))\n",
    "X = np.array(Xlist.tolist())\n",
    "y = [x[1] for x in my_data]\n",
    "\n",
    "for x in range(5):\n",
    "    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.33)\n",
    "    clf = RandomForestClassifier(n_estimators=100, min_samples_split=2)\n",
    "    clf.fit(Xtr, ytr)\n",
    "    print(np.mean(clf.predict(Xte) == yte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1797   26 1798   40   30   34    0   43   29    8]\n",
      "0.8081617086193745\n",
      "[1797   26 1798   40   30    0   34   43   22   29]\n",
      "0.8119755911517925\n",
      "[1797   26 1798   40    0   30   34   43 1799    8]\n",
      "0.8005339435545386\n",
      "[1797   26 1798   40   30    0   34   43   29 1799]\n",
      "0.8012967200610221\n",
      "[1797   26 1798   40    0   30   34   43   29 1799]\n",
      "0.8154080854309688\n"
     ]
    }
   ],
   "source": [
    "def name_count7(name):\n",
    "    arr = np.zeros(1800)\n",
    "    # Iterate each character\n",
    "    for ind, x in enumerate(name):\n",
    "        arr[ord(x)-ord('a')] += 1\n",
    "        arr[ord(x)-ord('a')+26] += ind+1\n",
    "    # Iterate every 2 characters\n",
    "    for x in range(len(name)-1):\n",
    "        ind = (ord(name[x])-ord('a'))*26 + (ord(name[x+1])-ord('a')) + 52\n",
    "        arr[ind] += 1\n",
    "    # Last character\n",
    "    arr[-3] = ord(name[-1])-ord('a')+1\n",
    "    # Second Last character\n",
    "    arr[-2] = ord(name[-2])-ord('a')+1\n",
    "    # Length of name\n",
    "    arr[-1] = len(name)\n",
    "    return arr\n",
    "\n",
    "name_map7 = np.vectorize(name_count7, otypes=[np.ndarray])\n",
    "Xlist = name_map7(np.asarray(list(zip(*my_data))[0],dtype=str))\n",
    "X = np.array(Xlist.tolist())\n",
    "y = [x[1] for x in my_data]\n",
    "\n",
    "for x in range(5):\n",
    "    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.33)\n",
    "    clf = RandomForestClassifier(n_estimators=150, min_samples_split=20)\n",
    "    clf.fit(Xtr, ytr)\n",
    "    print(clf.feature_importances_.argsort()[-10:][::-1])\n",
    "    print(np.mean(clf.predict(Xte) == yte))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code trains a model based on the last letter of the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.761632341723875\n",
      "0.7715484363081617\n",
      "0.7528604118993135\n",
      "0.7570556826849733\n",
      "0.7589626239511823\n"
     ]
    }
   ],
   "source": [
    "def name_count8(name):\n",
    "    arr = np.zeros(1)\n",
    "    arr[0] = ord(name[-1])-ord('a')+1\n",
    "    return arr\n",
    "\n",
    "name_map8 = np.vectorize(name_count8, otypes=[np.ndarray])\n",
    "Xlist = name_map8(np.asarray(list(zip(*my_data))[0],dtype=str))\n",
    "X = np.array(Xlist.tolist())\n",
    "y = [x[1] for x in my_data]\n",
    "\n",
    "for x in range(5):\n",
    "    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.33)\n",
    "    clf = RandomForestClassifier(n_estimators=150, min_samples_split=20)\n",
    "    clf.fit(Xtr, ytr)\n",
    "    print(np.mean(clf.predict(Xte) == yte))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code trains a model based on the last three letters of the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7890922959572845\n",
      "0.7913806254767353\n",
      "0.8012967200610221\n",
      "0.7940503432494279\n",
      "0.8032036613272311\n"
     ]
    }
   ],
   "source": [
    "def name_count9(name):\n",
    "    arr = np.zeros(3)\n",
    "    arr[0] = ord(name[-1])-ord('a')+1\n",
    "    arr[1] = ord(name[-2])-ord('a')+1\n",
    "    for ind, x in enumerate(name):\n",
    "        if len(name)>=3:\n",
    "            arr[2] = ord(name[-3])-ord('a')+1\n",
    "    \n",
    "    return arr\n",
    "\n",
    "name_map9 = np.vectorize(name_count9, otypes=[np.ndarray])\n",
    "Xlist = name_map9(np.asarray(list(zip(*my_data))[0],dtype=str))\n",
    "X = np.array(Xlist.tolist())\n",
    "y = [x[1] for x in my_data]\n",
    "\n",
    "for x in range(5):\n",
    "    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.33)\n",
    "    clf = RandomForestClassifier(n_estimators=150, min_samples_split=20)\n",
    "    clf.fit(Xtr, ytr)\n",
    "    print(np.mean(clf.predict(Xte) == yte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7784134248665141\n",
      "0.7738367658276125\n",
      "0.7734553775743707\n",
      "0.7837528604118993\n",
      "0.7738367658276125\n"
     ]
    }
   ],
   "source": [
    "def name_count10(name):\n",
    "    arr = np.zeros(3)\n",
    "    arr[0] = ord(name[-1])-ord('a')+1\n",
    "    arr[1] = ord(name[-2])-ord('a')+1\n",
    "    # Order of a's\n",
    "    for ind, x in enumerate(name):\n",
    "        if x == 'a':\n",
    "            arr[2] += ind+1\n",
    "    \n",
    "    return arr\n",
    "\n",
    "name_map10 = np.vectorize(name_count10, otypes=[np.ndarray])\n",
    "Xlist = name_map10(np.asarray(list(zip(*my_data))[0],dtype=str))\n",
    "X = np.array(Xlist.tolist())\n",
    "y = [x[1] for x in my_data]\n",
    "\n",
    "for x in range(5):\n",
    "    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.33)\n",
    "    clf = RandomForestClassifier(n_estimators=150, min_samples_split=20)\n",
    "    clf.fit(Xtr, ytr)\n",
    "    print(np.mean(clf.predict(Xte) == yte))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reid M M\n",
      "galina F F\n",
      "bishop M M\n",
      "channa F F\n",
      "uta F F\n",
      "tracy M M\n",
      "gillian F M\n",
      "cindi F F\n",
      "eustacia F F\n",
      "raleigh M M\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.choice(np.arange(len(Xlist)), 10, replace=False)\n",
    "Xname = [x[0] for x in my_data]\n",
    "xs = [Xname[x] for x in idx]\n",
    "ys = [y[x] for x in idx]\n",
    "pred = clf.predict(X[idx])\n",
    "\n",
    "for a,b, p in zip(xs,ys, pred):\n",
    "    print(a,b, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18.  9. 13.]\n",
      "aamir\n",
      "[14. 15. 18.]\n",
      "aaron\n",
      "[25.  5.  2.]\n",
      "abbey\n",
      "[5. 9. 2.]\n",
      "abbie\n",
      "[20. 15.  2.]\n",
      "abbot\n"
     ]
    }
   ],
   "source": [
    "for x in range(5): \n",
    "    print(X[x])\n",
    "    print(Xname[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The last-three letters model performs the best when trained on naive Bayes via ```nltk``` or in ```sklearn```.\n",
    "\n",
    "An interesting project for further study would be to add weights to the names based on the number of people who have each name so that more common names more heavily tilt the model. While this might not produce a more accurate result looking at a list of names, it should be more accurate when dealing with new, real-world data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
