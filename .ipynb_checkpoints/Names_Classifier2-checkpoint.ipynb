{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data 620, Project 3\n",
    "July 10, 2019 \n",
    "Team 6: Alice Friedman, Scott Jones, Jeff Littlejohn, and Jun Pan\n",
    "\n",
    "## Assignment Description\n",
    "Using any of the three classifiers described in chapter 6 of Natural Language Processing with Python, and any features you can think of, build the best name gender classifier you can. Begin by splitting the Names Corpus into three subsets: 500 words for the test set, 500 words for the devtest set, and the remaining 6900 words for the training set. Then, starting with the example name gender classifier, make incremental improvements. Use the dev-test set to check your progress. Once you are satisfied with your classifier, check its final performance on the test set. How does the performance on the test set compare to the performance on the dev-test set? Is this what you'd expect?\n",
    "\n",
    "Source: Natural Language Processing with Python, exercise 6.10.2.\n",
    "\n",
    "## Text Classification: Identifying Gender from the ```NLTK``` Names Corpus  \n",
    "\n",
    "### `nltk`  \n",
    "\n",
    "Adapted from the site: \n",
    "https://gist.github.com/vinovator/6e5bf1e1bc61687a1e809780c30d6bf6\n",
    "https://www.geeksforgeeks.org/python-gender-identification-by-name-using-nltk/\n",
    "\n",
    "### Setup\n",
    "\n",
    "First, we import the names corpus from the ```nltk``` list of corpuses, and create three sets of names. All sets will be of equal length and generated from a randomized shuffle of each of the corpuses.\n",
    "\n",
    "- A training set, used to train the model based on our selected features\n",
    "\n",
    "- A couple of \"dev\" sets, which we will use to test progress on the gender identifier and perform error analysis\n",
    "\n",
    "- A final \"test\" set, which we will use to test how well our predictions ultimately worked\n",
    "\n",
    "We will attempt XXX different versions of the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import names\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Lucio', 'male'), ('Donal', 'male'), ('Markus', 'male'), ('Iago', 'male'), ('Kelsey', 'male')] 2943\n",
      "[('Antoinette', 'female'), ('Lorilyn', 'female'), ('Letti', 'female'), ('Ella', 'female'), ('Corry', 'female')] 5001\n",
      "[('Niall', 'male'), ('Munroe', 'male'), ('Samuella', 'female'), ('Francis', 'female'), ('Zoe', 'female')] 7944\n"
     ]
    }
   ],
   "source": [
    "mcorpus = [(name, \"male\") for name in names.words(\"male.txt\")]\n",
    "fcorpus = [(name, \"female\") for name in names.words(\"female.txt\")]\n",
    "random.shuffle(mcorpus); random.shuffle(fcorpus)\n",
    "print(mcorpus[0:5],len(mcorpus))\n",
    "print(fcorpus[0:5],len(fcorpus))\n",
    "\n",
    "corpus = mcorpus + fcorpus\n",
    "random.shuffle(corpus)\n",
    "print(corpus[:5], len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert Data Viz?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function definitions to process and classify the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python slices lists from the first index up to *but not including* the second given index. This is counter-intutive, but ultimately makes it easier to slice lists consecutively as '''list[:10] + lists[10:]''' will return the complete, original list.\n",
    "\n",
    "From the textbook: \"Each time the error analysis is repeated, we should select a *different* dev-test/training split, to ensure that the classifier does not start to reflect the idiosyncracies in the dev-test set.\" (pg 227)\n",
    "\n",
    "To prevent a lot of re-coding, we can write a function to remix the development-training corpus, after setting aside the first 500 male and female names as the final test slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to return a new training and dev-test mix of the corpus for each iteration of the model\n",
    "def reslicer(corpus):\n",
    "    print(\"Reslicer returns 3 sliced, remixed set of corpuses:\")\n",
    "    print(\"\\tThe first returned value is the remixed training corpus, length is variable\")\n",
    "    print(\"\\tThe second returned value is the remixed dev-test corpus, length is 500\")\n",
    "    print(\"\\tThe third returned value is the un-remixed test set, length is 500\\n\")\n",
    "    final_test_n = 500 # can be adjusted\n",
    "    dev_test_n = 500 # can be adjusted\n",
    "    \n",
    "    test_corpus = corpus[:final_test_n] #reserve first 500 for the final test\n",
    "    print(\"Test Corpus Sample: \", test_corpus[0:3], \", Length: \", len(test_corpus))\n",
    "    \n",
    "    dev_set = corpus[final_test_n:] #create a copy of the dev_set to preserve the original test set before shuffling\n",
    "    random.shuffle(dev_set) #remix before re-slicing\n",
    "    \n",
    "    dev_test_corpus = dev_set[:dev_test_n]\n",
    "    print(\"Dev-Test Corpus Sample: \",dev_test_corpus[0:3], \", Length: \", len(dev_test_corpus)) #should have length 500\n",
    "    \n",
    "    train_corpus = dev_set[dev_test_n:]\n",
    "    print(\"Training Corpus Sample: \",train_corpus[0:3], \", Length: \", len(train_corpus)) #should be longer\n",
    "\n",
    "    return train_corpus, dev_test_corpus, test_corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reslicer returns 3 sliced, remixed set of corpuses:\n",
      "\tThe first returned value is the remixed training corpus, length is variable\n",
      "\tThe second returned value is the remixed dev-test corpus, length is 500\n",
      "\tThe third returned value is the un-remixed test set, length is 500\n",
      "\n",
      "Test Corpus Sample:  [('Niall', 'male'), ('Munroe', 'male'), ('Samuella', 'female')] , Length:  500\n",
      "Dev-Test Corpus Sample:  [('Rosie', 'female'), ('Constantia', 'female'), ('Laurens', 'male')] , Length:  500\n",
      "Training Corpus Sample:  [('Catherine', 'female'), ('Gilligan', 'female'), ('Eliott', 'male')] , Length:  6944\n"
     ]
    }
   ],
   "source": [
    "train_names, dev_names, test_names = reslicer(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Corpus Sample:  [('Niall', 'male'), ('Munroe', 'male'), ('Samuella', 'female')] , Length:  500\n",
      "Dev-Test Corpus Sample:  [('Greg', 'male'), ('Camille', 'female'), ('Frannie', 'female')] , Length:  500\n",
      "Training Corpus Sample:  [('Belita', 'female'), ('Marijo', 'female'), ('Gunvor', 'female')] , Length:  6944\n"
     ]
    }
   ],
   "source": [
    "#re-running the code will remix the training and dev-test sets, while leaving the original test names intact\n",
    "train_names, dev_names, test_names = reslicer(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we will be changing the feature function each time, we can create a series of functions to process and classify the data to to minimize repeated code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to process the names through feature extractor\n",
    "def feature_ext(feature_func, corpus):\n",
    "    \n",
    "    #first, remix and reslice the data to ensure we are using a new mix of dev-test and training data each time\n",
    "    train_names, dev_names, test_names = reslicer(corpus)\n",
    "    \n",
    "    #then, extract features from the names slices\n",
    "    train_set = [(feature_func(n), gender) for (n, gender) in train_names]\n",
    "    devtest_set = [(feature_func(n), gender) for (n, gender) in dev_names]\n",
    "    test_set = [(feature_func(n), gender) for (n, gender) in test_names]\n",
    "    \n",
    "    return train_set, devtest_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(feature_func, corpus):\n",
    "    feature_func = feature_func #use feature function given as arg\n",
    "    corpus = corpus\n",
    "    \n",
    "    # Run the feature_ext function to create the necessary labeled feature sets\n",
    "    train_set, devtest_set, test_set = feature_ext(feature_func, corpus)\n",
    "    \n",
    "    # Train the naiveBayes classifier\n",
    "    classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "    # Test the accuracy of the classifier on the dev data--this is so we can evaluate errors and make tweaks\n",
    "    a = round(nltk.classify.accuracy(classifier, devtest_set), 4)*100\n",
    "    accuracy = f'{a:.2f}'\n",
    "    print(\"\\n\")\n",
    "    print(\"Model is %s percent accurate\" % accuracy)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # examine classifier to determine which last letter is most effective for predicting gender\n",
    "    print(classifier.show_most_informative_features(10))\n",
    "    \n",
    "    #find errors\n",
    "    \n",
    "    def find_errors(dev_names, feature_func):\n",
    "    \n",
    "        errors = {'name' : [], 'label' : [], 'guess' : [], 'features': [] }\n",
    "        \n",
    "        for (name, label) in dev_names:\n",
    "            guess = classifier.classify(feature_func(name))\n",
    "            features = feature_func(name)\n",
    "            if guess != label:\n",
    "                errors['name'].append(name)\n",
    "                errors['label'].append(label)\n",
    "                errors['guess'].append(guess)\n",
    "                errors['features'].append(features)\n",
    "        \n",
    "        errors = pd.DataFrame(errors)\n",
    "        \n",
    "        #prints sample \n",
    "        print(\"\\nErrors\")\n",
    "        print(errors.sample(20))\n",
    "    \n",
    "    errors = find_errors(dev_names, feature_func)\n",
    "    \n",
    "    return classifier\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on the last letter of the name\n",
    "\n",
    "Now that we have our functions set up, we can define some differnt feature extraction functions and test each one.\n",
    "\n",
    "First, we will test a model by examining only the last letter of each name. We will use ```nltk```'s built-in Naive Baysian Classifier to train the model based on this feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_letter(word): #first feature functiont to test\n",
    "    \n",
    "    return {\"last_letter\": word[-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Corpus Sample:  [('Niall', 'male'), ('Munroe', 'male'), ('Samuella', 'female')] , Length:  500\n",
      "Dev-Test Corpus Sample:  [('Bernadette', 'female'), ('Kanya', 'female'), ('Nan', 'female')] , Length:  500\n",
      "Training Corpus Sample:  [('Shelden', 'male'), ('Eugene', 'male'), ('Staffard', 'male')] , Length:  6944\n",
      "\n",
      "\n",
      "Model is 74.80 percent accurate\n",
      "\n",
      "\n",
      "Most Informative Features\n",
      "             last_letter = 'a'            female : male   =     39.7 : 1.0\n",
      "             last_letter = 'k'              male : female =     28.8 : 1.0\n",
      "             last_letter = 'f'              male : female =     25.4 : 1.0\n",
      "             last_letter = 'p'              male : female =     11.2 : 1.0\n",
      "             last_letter = 'v'              male : female =      9.8 : 1.0\n",
      "             last_letter = 'd'              male : female =      9.4 : 1.0\n",
      "             last_letter = 'm'              male : female =      8.6 : 1.0\n",
      "             last_letter = 'o'              male : female =      7.9 : 1.0\n",
      "             last_letter = 'r'              male : female =      6.3 : 1.0\n",
      "             last_letter = 'b'              male : female =      5.4 : 1.0\n",
      "None\n",
      "\n",
      "Errors\n",
      "         name   label   guess              features\n",
      "62    Michele    male  female  {'last_letter': 'e'}\n",
      "30     Austin  female    male  {'last_letter': 'n'}\n",
      "91      Marlo  female    male  {'last_letter': 'o'}\n",
      "76     Nevile    male  female  {'last_letter': 'e'}\n",
      "23     Gretal  female    male  {'last_letter': 'l'}\n",
      "52    Maribel  female    male  {'last_letter': 'l'}\n",
      "101      Levi    male  female  {'last_letter': 'i'}\n",
      "48       Tony    male  female  {'last_letter': 'y'}\n",
      "33       Rich    male  female  {'last_letter': 'h'}\n",
      "90     Easter  female    male  {'last_letter': 'r'}\n",
      "27      Reiko  female    male  {'last_letter': 'o'}\n",
      "95      Paddy    male  female  {'last_letter': 'y'}\n",
      "102  Margeaux  female    male  {'last_letter': 'x'}\n",
      "22       Bren  female    male  {'last_letter': 'n'}\n",
      "10    Jacklyn  female    male  {'last_letter': 'n'}\n",
      "109       Bev  female    male  {'last_letter': 'v'}\n",
      "85      Sasha    male  female  {'last_letter': 'a'}\n",
      "117    Murphy    male  female  {'last_letter': 'y'}\n",
      "36     Temple    male  female  {'last_letter': 'e'}\n",
      "67    Frankie    male  female  {'last_letter': 'e'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<nltk.classify.naivebayes.NaiveBayesClassifier at 0x12425c7f0>"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(last_letter, corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are interesting results! Ending in `a` is the *only* letter in the top ten that predicts female names instead of male names. \n",
    "\n",
    "Does this basic model work for our names? Let's write a short script to test our names and print a result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on the last 3 letters of the name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we try adding the last 3 letters as well as just the last letter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reslicer returns 3 sliced, remixed set of corpuses:\n",
      "\tThe first returned value is the remixed training corpus, length is variable\n",
      "\tThe second returned value is the remixed dev-test corpus, length is 500\n",
      "\tThe third returned value is the un-remixed test set, length is 500\n",
      "\n",
      "Test Corpus Sample:  [('Niall', 'male'), ('Munroe', 'male'), ('Samuella', 'female')] , Length:  500\n",
      "Dev-Test Corpus Sample:  [('Terrence', 'male'), ('Lazar', 'male'), ('Jessey', 'male')] , Length:  500\n",
      "Training Corpus Sample:  [('Kelly', 'female'), ('Manny', 'male'), ('Merlin', 'male')] , Length:  6944\n",
      "\n",
      "\n",
      "Model is 79.00 percent accurate\n",
      "\n",
      "\n",
      "Most Informative Features\n",
      "             last_letter = 'a'            female : male   =     43.0 : 1.0\n",
      "             last_letter = 'k'              male : female =     41.4 : 1.0\n",
      "             last_letter = 'f'              male : female =     27.5 : 1.0\n",
      "            last3letters = 'ita'          female : male   =     25.4 : 1.0\n",
      "            last3letters = 'ard'            male : female =     24.3 : 1.0\n",
      "            last3letters = 'tta'          female : male   =     21.9 : 1.0\n",
      "             last_letter = 'p'              male : female =     20.8 : 1.0\n",
      "            last3letters = 'nne'          female : male   =     18.9 : 1.0\n",
      "            last3letters = 'ert'            male : female =     18.1 : 1.0\n",
      "            last3letters = 'vin'            male : female =     16.9 : 1.0\n",
      "None\n",
      "\n",
      "Errors\n",
      "        name   label   guess                                     features\n",
      "65    Linnet  female    male  {'last_letter': 't', 'last3letters': 'net'}\n",
      "77     Holly    male  female  {'last_letter': 'y', 'last3letters': 'lly'}\n",
      "19     Noble    male  female  {'last_letter': 'e', 'last3letters': 'ble'}\n",
      "48    Harley  female    male  {'last_letter': 'y', 'last3letters': 'ley'}\n",
      "12    Farand  female    male  {'last_letter': 'd', 'last3letters': 'and'}\n",
      "69   Caitrin  female    male  {'last_letter': 'n', 'last3letters': 'rin'}\n",
      "45  Timothee    male  female  {'last_letter': 'e', 'last3letters': 'hee'}\n",
      "13     Ambur  female    male  {'last_letter': 'r', 'last3letters': 'bur'}\n",
      "21     Sasha    male  female  {'last_letter': 'a', 'last3letters': 'sha'}\n",
      "75    Hamlen    male  female  {'last_letter': 'n', 'last3letters': 'len'}\n",
      "61     Gwenn  female    male  {'last_letter': 'n', 'last3letters': 'enn'}\n",
      "8      Loren  female    male  {'last_letter': 'n', 'last3letters': 'ren'}\n",
      "40     Davie    male  female  {'last_letter': 'e', 'last3letters': 'vie'}\n",
      "57     Piper  female    male  {'last_letter': 'r', 'last3letters': 'per'}\n",
      "14    Dorian  female    male  {'last_letter': 'n', 'last3letters': 'ian'}\n",
      "20      Dani    male  female  {'last_letter': 'i', 'last3letters': 'ani'}\n",
      "72    Neddie    male  female  {'last_letter': 'e', 'last3letters': 'die'}\n",
      "83     Barri    male  female  {'last_letter': 'i', 'last3letters': 'rri'}\n",
      "30    Daryle    male  female  {'last_letter': 'e', 'last3letters': 'yle'}\n",
      "5     Ginger  female    male  {'last_letter': 'r', 'last3letters': 'ger'}\n"
     ]
    }
   ],
   "source": [
    "def two_features(word):\n",
    "    return {\"last_letter\": word[-1], \"last3letters\": word[-3:]}  # feature set\n",
    "\n",
    "#note, we are automatically re-slicing the training/dev-test slices\n",
    "two_features_classifier = test_model(two_features, corpus) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the last three letters increased our accuracy by about 5 percentage points! Let's see if we can learn anything from the remaining errors to improve our model further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maybe can cut this section -- or use for more error analysis?\n",
    "\n",
    "I think besides data viz, the main thing we are missing here is error analysis leading to new feature extractions, e.g. because it missed  \"Tracy\" we will try...\n",
    "\n",
    "An additional analysis we could do would be to extract names like \"Tracy\", \"Laurie\", \"Leslie\" that appear in *both* the male and female lists--there aren't really being coded \"incorrectly\" but they will count as errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ### Analysis of name parts\n",
    "   \n",
    "Next, let's take a look at whether the presence or absense of any letters or consecutive groups of letters can tell us anything about the names by doing an analysis.\n",
    "\n",
    "First, we create a function that returns all the combinations consecutive letters in a name, except the name itself. So, for example, in the name, \"Noah\", it returns the list:\n",
    "```['N', 'No', 'Noa', 'o', 'oa', 'oah', 'a', 'ah', 'h']```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N', 'No', 'Noa', 'Noah', 'o', 'oa', 'oah', 'a', 'ah', 'h']\n"
     ]
    }
   ],
   "source": [
    "def name_parts(name):\n",
    "    i = 0\n",
    "    letters = ''\n",
    "    parts = []\n",
    "    ans = ''\n",
    "    for letter in name:\n",
    "        next_part = name[i:]\n",
    "        for letter in next_part:\n",
    "            letters += letter\n",
    "            parts.append(letters)\n",
    "            i+=0\n",
    "        letters=''\n",
    "        i += 1\n",
    "    return parts\n",
    "print(name_parts(\"Noah\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parts_set(labeled_names):\n",
    "    parts_set = []\n",
    "    for name, label in labeled_names:\n",
    "        features_list = name_parts(name)\n",
    "        #print(features_list)\n",
    "        parts_list = [(item, label) for item in features_list]\n",
    "        #print(parts_list)\n",
    "        parts_set += parts_list\n",
    "        #print(parts_set)\n",
    "    return parts_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add data viz here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Corpus Sample:  [('Niall', 'male'), ('Munroe', 'male'), ('Samuella', 'female')] , Length:  500\n",
      "Dev-Test Corpus Sample:  [('Janeczka', 'female'), ('Lauretta', 'female'), ('Rod', 'male')] , Length:  500\n",
      "Training Corpus Sample:  [('Gustav', 'male'), ('Russell', 'male'), ('Haily', 'female')] , Length:  6944\n"
     ]
    }
   ],
   "source": [
    "train_names, dev_names, test_names = reslicer(corpus)\n",
    "train_set2 = parts_set(train_names)\n",
    "dev_set2 = parts_set(dev_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Model is 67.00 percent accurate\n",
      "\n",
      "\n",
      "Most Informative Features\n",
      "                 feature = 'nna'          female : male   =     38.2 : 1.0\n",
      "                 feature = 'tte'          female : male   =     37.8 : 1.0\n",
      "                 feature = 'rv'             male : female =     28.8 : 1.0\n",
      "                 feature = 'tta'          female : male   =     22.3 : 1.0\n",
      "                 feature = 'ing'            male : female =     19.0 : 1.0\n",
      "                 feature = 'hu'             male : female =     19.0 : 1.0\n",
      "                 feature = 'anna'         female : male   =     18.2 : 1.0\n",
      "                 feature = 'bel'          female : male   =     17.4 : 1.0\n",
      "                 feature = 'etta'         female : male   =     17.4 : 1.0\n",
      "                 feature = 'ton'            male : female =     17.0 : 1.0\n",
      "                 feature = 'iu'             male : female =     16.8 : 1.0\n",
      "                 feature = 'son'            male : female =     16.1 : 1.0\n",
      "                 feature = 'Ros'          female : male   =     15.7 : 1.0\n",
      "                 feature = 'ita'          female : male   =     15.1 : 1.0\n",
      "                 feature = 'ina'          female : male   =     15.0 : 1.0\n",
      "                 feature = 'lt'             male : female =     14.7 : 1.0\n",
      "                 feature = 'rw'             male : female =     14.7 : 1.0\n",
      "                 feature = 'ora'          female : male   =     14.4 : 1.0\n",
      "                 feature = 'rk'             male : female =     14.0 : 1.0\n",
      "                 feature = 'nia'          female : male   =     13.7 : 1.0\n",
      "                 feature = 'iss'          female : male   =     13.6 : 1.0\n",
      "                 feature = 'ner'            male : female =     13.6 : 1.0\n",
      "                 feature = 'wa'             male : female =     13.6 : 1.0\n",
      "                 feature = 'Tha'            male : female =     13.6 : 1.0\n",
      "                 feature = 'win'            male : female =     13.6 : 1.0\n",
      "                 feature = 'elle'         female : male   =     13.6 : 1.0\n",
      "                 feature = 'rina'         female : male   =     13.3 : 1.0\n",
      "                 feature = 'ssa'          female : male   =     12.6 : 1.0\n",
      "                 feature = 'rick'           male : female =     12.1 : 1.0\n",
      "                 feature = 'Cat'          female : male   =     11.7 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Train the naiveBayes classifier\n",
    "classifier2 = nltk.NaiveBayesClassifier.train(train_set2)\n",
    "\n",
    "a = round(nltk.classify.accuracy(classifier2, dev_set2), 4)*100\n",
    "accuracy = f'{a:.2f}'\n",
    "print(\"\\n\")\n",
    "print(\"Model is %s percent accurate\" % accuracy)\n",
    "print(\"\\n\")\n",
    "\n",
    "# examine classifier to determine which feature is most effective for predicting the name's gender\n",
    "print(classifier2.show_most_informative_features(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This actually made it worse! Maybe we can combine some of these most important features with our previous model to close the gap even further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'last_letter': 'O', 'last3letters': 'BO', 'high_val_features': ''}\n",
      "{'last_letter': 'a', 'last3letters': 'tta', 'high_val_features': 'etta'}\n",
      "{'last_letter': 'a', 'last3letters': 'ita', 'high_val_features': 'Ros'}\n"
     ]
    }
   ],
   "source": [
    "#features with a greater than 15:1 predictive value\n",
    "high_val_features = ['nna', 'tte', 'rv', 'hu', 'anna', 'bel', 'etta', 'ton', 'iu', 'son', 'Ros', 'ita', 'ina']\n",
    "\n",
    "def combo_features(name):\n",
    "    feature_set = {\"last_letter\": name[-1], \"last3letters\": name[-3:], 'high_val_features': ''}\n",
    "    parts = name_parts(name)\n",
    "    for feature in high_val_features:\n",
    "        if feature in parts:\n",
    "                feature_set.update({'high_val_features' : feature})\n",
    "                break\n",
    "    return feature_set\n",
    "\n",
    "print(combo_features(\"BO\"))\n",
    "print(combo_features(\"Henrietta\"))\n",
    "print(combo_features(\"Rosita\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reslicer returns 3 sliced, remixed set of corpuses:\n",
      "\tThe first returned value is the remixed training corpus, length is variable\n",
      "\tThe second returned value is the remixed dev-test corpus, length is 500\n",
      "\tThe third returned value is the un-remixed test set, length is 500\n",
      "\n",
      "Test Corpus Sample:  [('Niall', 'male'), ('Munroe', 'male'), ('Samuella', 'female')] , Length:  500\n",
      "Dev-Test Corpus Sample:  [('Samuel', 'male'), ('Leslie', 'female'), ('Rolph', 'male')] , Length:  500\n",
      "Training Corpus Sample:  [('Annalena', 'female'), ('Sherry', 'female'), ('Davina', 'female')] , Length:  6944\n",
      "\n",
      "\n",
      "Model is 78.60 percent accurate\n",
      "\n",
      "\n",
      "Most Informative Features\n",
      "             last_letter = 'a'            female : male   =     42.7 : 1.0\n",
      "       high_val_features = 'nna'          female : male   =     36.9 : 1.0\n",
      "       high_val_features = 'rv'             male : female =     32.4 : 1.0\n",
      "             last_letter = 'k'              male : female =     30.5 : 1.0\n",
      "             last_letter = 'f'              male : female =     27.9 : 1.0\n",
      "            last3letters = 'ert'            male : female =     27.5 : 1.0\n",
      "       high_val_features = 'ton'            male : female =     26.1 : 1.0\n",
      "            last3letters = 'ita'          female : male   =     26.0 : 1.0\n",
      "            last3letters = 'ana'          female : male   =     23.4 : 1.0\n",
      "            last3letters = 'tta'          female : male   =     22.1 : 1.0\n",
      "None\n",
      "\n",
      "Errors\n",
      "        name   label   guess  \\\n",
      "66     Regan  female    male   \n",
      "68      Dale  female    male   \n",
      "69    Kerrin  female    male   \n",
      "57      Drew  female    male   \n",
      "50    Jeffie    male  female   \n",
      "21   Deloris  female    male   \n",
      "53  Jaquelin  female    male   \n",
      "76     Brier  female    male   \n",
      "9      Luigi    male  female   \n",
      "58    Esther  female    male   \n",
      "42    Felice    male  female   \n",
      "28     Pryce    male  female   \n",
      "52     Piper  female    male   \n",
      "54        Si    male  female   \n",
      "62    Carley  female    male   \n",
      "71    Myriam  female    male   \n",
      "31    Nevile    male  female   \n",
      "81     Ronny    male  female   \n",
      "44    Elmore    male  female   \n",
      "77      Kyle    male  female   \n",
      "\n",
      "                                             features  \n",
      "66  {'last_letter': 'n', 'last3letters': 'gan', 'h...  \n",
      "68  {'last_letter': 'e', 'last3letters': 'ale', 'h...  \n",
      "69  {'last_letter': 'n', 'last3letters': 'rin', 'h...  \n",
      "57  {'last_letter': 'w', 'last3letters': 'rew', 'h...  \n",
      "50  {'last_letter': 'e', 'last3letters': 'fie', 'h...  \n",
      "21  {'last_letter': 's', 'last3letters': 'ris', 'h...  \n",
      "53  {'last_letter': 'n', 'last3letters': 'lin', 'h...  \n",
      "76  {'last_letter': 'r', 'last3letters': 'ier', 'h...  \n",
      "9   {'last_letter': 'i', 'last3letters': 'igi', 'h...  \n",
      "58  {'last_letter': 'r', 'last3letters': 'her', 'h...  \n",
      "42  {'last_letter': 'e', 'last3letters': 'ice', 'h...  \n",
      "28  {'last_letter': 'e', 'last3letters': 'yce', 'h...  \n",
      "52  {'last_letter': 'r', 'last3letters': 'per', 'h...  \n",
      "54  {'last_letter': 'i', 'last3letters': 'Si', 'hi...  \n",
      "62  {'last_letter': 'y', 'last3letters': 'ley', 'h...  \n",
      "71  {'last_letter': 'm', 'last3letters': 'iam', 'h...  \n",
      "31  {'last_letter': 'e', 'last3letters': 'ile', 'h...  \n",
      "81  {'last_letter': 'y', 'last3letters': 'nny', 'h...  \n",
      "44  {'last_letter': 'e', 'last3letters': 'ore', 'h...  \n",
      "77  {'last_letter': 'e', 'last3letters': 'yle', 'h...  \n"
     ]
    }
   ],
   "source": [
    "#test model using new feature extractor\n",
    "combo_classifier = test_model(combo_features, corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This last bit didn't help much. Still, it's roughly as good as the two_features, so let's go ahead and test both and the on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THIS PART IS NOT WORKING--NEED TO TEST THE MODELS ON THE TEST SET### \n",
    "train_set, dev_set, test_set = reslicer(corpus)\n",
    "\n",
    "def final_test(classifier, test_set):\n",
    "    # Test the accuracy of the classifier on the dev data--this is so we can evaluate errors and make tweaks\n",
    "    a = round(nltk.classify.accuracy(classifier, test_set), 4)*100\n",
    "    accuracy = f'{a:.2f}'\n",
    "    print(\"\\n\")\n",
    "    print(\"Model is %s percent accurate\" % accuracy)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "\n",
    "final_test(two_features_classifier, test_set)\n",
    "final_test(combo_classifier, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In conclusion, the final test does not produce identical results when run on the test set (or even re-run on the development set). This should not be surprising because the model is making a prediction based on patterns that are not necessarily hard and fast rules. \n",
    "\n",
    "In addition, the corpus includes unisex names.\n",
    "\n",
    "An interesting project for further study would be to add weights to the names based on the number of people who have each name so that more common names more heavily tilt the model. While this might not produce a more accurate result looking at a list of names, it should be more accurate when dealing with new, real-world data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `sklearn`  \n",
    "\n",
    "From the site: https://blog.ayoungprogrammer.com/2016/04/determining-gender-of-name-with-80.html/    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the names corpus with gender assignment; each name is converted to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_names = ([(name.lower(), \"M\") for name in names.words(\"male.txt\")] +\n",
    "                 [(name.lower(), \"F\") for name in names.words(\"female.txt\")])\n",
    "\n",
    "my_data = np.asarray(labeled_names) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `sklearn`, we train a model on numbers associated with each letter in the name, where a=1, b=2, c=3, ... in this manner a model is created based on integer values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7219679633867276\n",
      "0.7292143401983219\n",
      "0.7315026697177727\n",
      "0.7257818459191457\n",
      "0.7265446224256293\n"
     ]
    }
   ],
   "source": [
    "def name_count(name):\n",
    "    arr = np.zeros(65)\n",
    "    for ind, x in enumerate(name):\n",
    "        arr[ord(x)-ord('a')] += 1\n",
    "    return arr\n",
    "\n",
    "name_map = np.vectorize(name_count, otypes=[np.ndarray])\n",
    "Xlist = name_map(np.asarray(list(zip(*my_data))[0],dtype=str))\n",
    "X = np.array(Xlist.tolist())\n",
    "y = [x[1] for x in my_data]\n",
    "\n",
    "for x in range(5):\n",
    "    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.33)\n",
    "    clf = RandomForestClassifier(n_estimators=100, min_samples_split=2)\n",
    "    clf.fit(Xtr, ytr)\n",
    "    print(np.mean(clf.predict(Xte) == yte))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7829900839054157\n",
      "0.7807017543859649\n",
      "0.7864225781845919\n",
      "0.7688787185354691\n",
      "0.7936689549961862\n"
     ]
    }
   ],
   "source": [
    "def name_count2(name):\n",
    "    arr = np.zeros(65+26)\n",
    "    for ind, x in enumerate(name):\n",
    "        arr[ord(x)-ord('a')] += 1\n",
    "        arr[ord(x)-ord('a')+26] += ind+1\n",
    "    return arr\n",
    "\n",
    "name_map2 = np.vectorize(name_count2, otypes=[np.ndarray])\n",
    "Xlist = name_map2(np.asarray(list(zip(*my_data))[0],dtype=str))\n",
    "X = np.array(Xlist.tolist())\n",
    "y = [x[1] for x in my_data]\n",
    "\n",
    "for x in range(5):\n",
    "    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.33)\n",
    "    clf = RandomForestClassifier(n_estimators=100, min_samples_split=2)\n",
    "    clf.fit(Xtr, ytr)\n",
    "    print(np.mean(clf.predict(Xte) == yte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7963386727688787\n",
      "0.7967200610221206\n",
      "0.7894736842105263\n",
      "0.7917620137299771\n",
      "0.7921434019832189\n"
     ]
    }
   ],
   "source": [
    "def name_count3(name):\n",
    "    arr = np.zeros(1800)\n",
    "    # Iterate each character\n",
    "    for ind, x in enumerate(name):\n",
    "        arr[ord(x)-ord('a')] += 1\n",
    "        arr[ord(x)-ord('a')+26] += ind+1\n",
    "    # Iterate every 2 characters\n",
    "    for x in range(len(name)-1):\n",
    "        ind = (ord(name[x])-ord('a'))*26 + (ord(name[x+1])-ord('a')) + 52\n",
    "        arr[ind] += 1\n",
    "    return arr\n",
    "\n",
    "name_map3 = np.vectorize(name_count3, otypes=[np.ndarray])\n",
    "Xlist = name_map3(np.asarray(list(zip(*my_data))[0],dtype=str))\n",
    "X = np.array(Xlist.tolist())\n",
    "y = [x[1] for x in my_data]\n",
    "\n",
    "for x in range(5):\n",
    "    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.33)\n",
    "    clf = RandomForestClassifier(n_estimators=100, min_samples_split=2)\n",
    "    clf.fit(Xtr, ytr)\n",
    "    print(np.mean(clf.predict(Xte) == yte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8180778032036613\n",
      "0.8188405797101449\n",
      "0.8096872616323417\n",
      "0.8032036613272311\n",
      "0.8081617086193745\n"
     ]
    }
   ],
   "source": [
    "def name_count4(name):\n",
    "    arr = np.zeros(1800)\n",
    "    # Iterate each character\n",
    "    for ind, x in enumerate(name):\n",
    "        arr[ord(x)-ord('a')] += 1\n",
    "        arr[ord(x)-ord('a')+26] += ind+1\n",
    "    # Iterate every 2 characters\n",
    "    for x in range(len(name)-1):\n",
    "        ind = (ord(name[x])-ord('a'))*26 + (ord(name[x+1])-ord('a')) + 52\n",
    "        arr[ind] += 1\n",
    "    # Last character\n",
    "    arr[-3] = ord(name[-1])-ord('a')+1\n",
    "    # Second Last character\n",
    "    arr[-2] = ord(name[-2])-ord('a')+1\n",
    "    # Length of name\n",
    "    arr[-1] = len(name)\n",
    "    return arr\n",
    "\n",
    "name_map4 = np.vectorize(name_count4, otypes=[np.ndarray])\n",
    "Xlist = name_map4(np.asarray(list(zip(*my_data))[0],dtype=str))\n",
    "X = np.array(Xlist.tolist())\n",
    "y = [x[1] for x in my_data]\n",
    "\n",
    "for x in range(5):\n",
    "    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.33)\n",
    "    clf = RandomForestClassifier(n_estimators=100, min_samples_split=2)\n",
    "    clf.fit(Xtr, ytr)\n",
    "    print(np.mean(clf.predict(Xte) == yte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1797   26 1798   40   30   34    0   43   29    8]\n",
      "0.8081617086193745\n",
      "[1797   26 1798   40   30    0   34   43   22   29]\n",
      "0.8119755911517925\n",
      "[1797   26 1798   40    0   30   34   43 1799    8]\n",
      "0.8005339435545386\n",
      "[1797   26 1798   40   30    0   34   43   29 1799]\n",
      "0.8012967200610221\n",
      "[1797   26 1798   40    0   30   34   43   29 1799]\n",
      "0.8154080854309688\n"
     ]
    }
   ],
   "source": [
    "def name_count7(name):\n",
    "    arr = np.zeros(1800)\n",
    "    # Iterate each character\n",
    "    for ind, x in enumerate(name):\n",
    "        arr[ord(x)-ord('a')] += 1\n",
    "        arr[ord(x)-ord('a')+26] += ind+1\n",
    "    # Iterate every 2 characters\n",
    "    for x in range(len(name)-1):\n",
    "        ind = (ord(name[x])-ord('a'))*26 + (ord(name[x+1])-ord('a')) + 52\n",
    "        arr[ind] += 1\n",
    "    # Last character\n",
    "    arr[-3] = ord(name[-1])-ord('a')+1\n",
    "    # Second Last character\n",
    "    arr[-2] = ord(name[-2])-ord('a')+1\n",
    "    # Length of name\n",
    "    arr[-1] = len(name)\n",
    "    return arr\n",
    "\n",
    "name_map7 = np.vectorize(name_count7, otypes=[np.ndarray])\n",
    "Xlist = name_map7(np.asarray(list(zip(*my_data))[0],dtype=str))\n",
    "X = np.array(Xlist.tolist())\n",
    "y = [x[1] for x in my_data]\n",
    "\n",
    "for x in range(5):\n",
    "    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.33)\n",
    "    clf = RandomForestClassifier(n_estimators=150, min_samples_split=20)\n",
    "    clf.fit(Xtr, ytr)\n",
    "    print(clf.feature_importances_.argsort()[-10:][::-1])\n",
    "    print(np.mean(clf.predict(Xte) == yte))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code trains a model based on the last letter of the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.761632341723875\n",
      "0.7715484363081617\n",
      "0.7528604118993135\n",
      "0.7570556826849733\n",
      "0.7589626239511823\n"
     ]
    }
   ],
   "source": [
    "def name_count8(name):\n",
    "    arr = np.zeros(1)\n",
    "    arr[0] = ord(name[-1])-ord('a')+1\n",
    "    return arr\n",
    "\n",
    "name_map8 = np.vectorize(name_count8, otypes=[np.ndarray])\n",
    "Xlist = name_map8(np.asarray(list(zip(*my_data))[0],dtype=str))\n",
    "X = np.array(Xlist.tolist())\n",
    "y = [x[1] for x in my_data]\n",
    "\n",
    "for x in range(5):\n",
    "    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.33)\n",
    "    clf = RandomForestClassifier(n_estimators=150, min_samples_split=20)\n",
    "    clf.fit(Xtr, ytr)\n",
    "    print(np.mean(clf.predict(Xte) == yte))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code trains a model based on the last three letters of the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7890922959572845\n",
      "0.7913806254767353\n",
      "0.8012967200610221\n",
      "0.7940503432494279\n",
      "0.8032036613272311\n"
     ]
    }
   ],
   "source": [
    "def name_count9(name):\n",
    "    arr = np.zeros(3)\n",
    "    arr[0] = ord(name[-1])-ord('a')+1\n",
    "    arr[1] = ord(name[-2])-ord('a')+1\n",
    "    for ind, x in enumerate(name):\n",
    "        if len(name)>=3:\n",
    "            arr[2] = ord(name[-3])-ord('a')+1\n",
    "    \n",
    "    return arr\n",
    "\n",
    "name_map9 = np.vectorize(name_count9, otypes=[np.ndarray])\n",
    "Xlist = name_map9(np.asarray(list(zip(*my_data))[0],dtype=str))\n",
    "X = np.array(Xlist.tolist())\n",
    "y = [x[1] for x in my_data]\n",
    "\n",
    "for x in range(5):\n",
    "    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.33)\n",
    "    clf = RandomForestClassifier(n_estimators=150, min_samples_split=20)\n",
    "    clf.fit(Xtr, ytr)\n",
    "    print(np.mean(clf.predict(Xte) == yte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7784134248665141\n",
      "0.7738367658276125\n",
      "0.7734553775743707\n",
      "0.7837528604118993\n",
      "0.7738367658276125\n"
     ]
    }
   ],
   "source": [
    "def name_count10(name):\n",
    "    arr = np.zeros(3)\n",
    "    arr[0] = ord(name[-1])-ord('a')+1\n",
    "    arr[1] = ord(name[-2])-ord('a')+1\n",
    "    # Order of a's\n",
    "    for ind, x in enumerate(name):\n",
    "        if x == 'a':\n",
    "            arr[2] += ind+1\n",
    "    \n",
    "    return arr\n",
    "\n",
    "name_map10 = np.vectorize(name_count10, otypes=[np.ndarray])\n",
    "Xlist = name_map10(np.asarray(list(zip(*my_data))[0],dtype=str))\n",
    "X = np.array(Xlist.tolist())\n",
    "y = [x[1] for x in my_data]\n",
    "\n",
    "for x in range(5):\n",
    "    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.33)\n",
    "    clf = RandomForestClassifier(n_estimators=150, min_samples_split=20)\n",
    "    clf.fit(Xtr, ytr)\n",
    "    print(np.mean(clf.predict(Xte) == yte))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reid M M\n",
      "galina F F\n",
      "bishop M M\n",
      "channa F F\n",
      "uta F F\n",
      "tracy M M\n",
      "gillian F M\n",
      "cindi F F\n",
      "eustacia F F\n",
      "raleigh M M\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.choice(np.arange(len(Xlist)), 10, replace=False)\n",
    "Xname = [x[0] for x in my_data]\n",
    "xs = [Xname[x] for x in idx]\n",
    "ys = [y[x] for x in idx]\n",
    "pred = clf.predict(X[idx])\n",
    "\n",
    "for a,b, p in zip(xs,ys, pred):\n",
    "    print(a,b, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18.  9. 13.]\n",
      "aamir\n",
      "[14. 15. 18.]\n",
      "aaron\n",
      "[25.  5.  2.]\n",
      "abbey\n",
      "[5. 9. 2.]\n",
      "abbie\n",
      "[20. 15.  2.]\n",
      "abbot\n"
     ]
    }
   ],
   "source": [
    "for x in range(5): \n",
    "    print(X[x])\n",
    "    print(Xname[x])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
