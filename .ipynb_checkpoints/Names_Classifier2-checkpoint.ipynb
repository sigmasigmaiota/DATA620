{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data 620, Project 3\n",
    "July 10, 2019 \n",
    "Team 6: Alice Friedman, Scott Jones, Jeff Littlejohn, and Jun Pan\n",
    "\n",
    "## Assignment Description\n",
    "Using any of the three classifiers described in chapter 6 of Natural Language Processing with Python, and any features you can think of, build the best name gender classifier you can. Begin by splitting the Names Corpus into three subsets: 500 words for the test set, 500 words for the devtest set, and the remaining 6900 words for the training set. Then, starting with the example name gender classifier, make incremental improvements. Use the dev-test set to check your progress. Once you are satisfied with your classifier, check its final performance on the test set. How does the performance on the test set compare to the performance on the dev-test set? Is this what you'd expect?\n",
    "\n",
    "Source: Natural Language Processing with Python, exercise 6.10.2.\n",
    "\n",
    "## Text Classification: Identifying Gender from the ```NLTK``` Names Corpus  \n",
    "\n",
    "### `nltk`  \n",
    "\n",
    "Adapted from the site: \n",
    "https://gist.github.com/vinovator/6e5bf1e1bc61687a1e809780c30d6bf6\n",
    "https://www.geeksforgeeks.org/python-gender-identification-by-name-using-nltk/\n",
    "\n",
    "### Setup\n",
    "\n",
    "First, we import the names corpus from the ```nltk``` list of corpuses, and create three sets of names. All sets will be of equal length and generated from a randomized shuffle of each of the corpuses.\n",
    "\n",
    "- A training set, used to train the model based on our selected features\n",
    "\n",
    "- A couple of \"dev\" sets, which we will use to test progress on the gender identifier and perform error analysis\n",
    "\n",
    "- A final \"test\" set, which we will use to test how well our predictions ultimately worked\n",
    "\n",
    "We will attempt XXX different versions of the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import names\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Lucio', 'male'), ('Donal', 'male'), ('Markus', 'male'), ('Iago', 'male'), ('Kelsey', 'male')] 2943\n",
      "[('Antoinette', 'female'), ('Lorilyn', 'female'), ('Letti', 'female'), ('Ella', 'female'), ('Corry', 'female')] 5001\n",
      "[('Niall', 'male'), ('Munroe', 'male'), ('Samuella', 'female'), ('Francis', 'female'), ('Zoe', 'female')] 7944\n"
     ]
    }
   ],
   "source": [
    "mcorpus = [(name, \"male\") for name in names.words(\"male.txt\")]\n",
    "fcorpus = [(name, \"female\") for name in names.words(\"female.txt\")]\n",
    "random.shuffle(mcorpus); random.shuffle(fcorpus)\n",
    "print(mcorpus[0:5],len(mcorpus))\n",
    "print(fcorpus[0:5],len(fcorpus))\n",
    "\n",
    "corpus = mcorpus + fcorpus\n",
    "random.shuffle(corpus)\n",
    "print(corpus[:5], len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python slices lists from the first index up to *but not including* the second given index. This is counter-intutive, but ultimately makes it easier to slice lists consecutively as '''list[:10] + lists[10:]''' will return the complete, original list.\n",
    "\n",
    "From the textbook: \"Each time the error analysis is repeated, we should select a *different* dev-test/training split, to ensure that the classifier does not start to reflect the idiosyncracies in the dev-test set.\" (pg 227)\n",
    "\n",
    "To prevent a lot of re-coding, we can write a function to remix the development-training corpus, after setting aside the first 500 male and female names as the final test slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to return a new training and dev-test mix of the corpus for each iteration of the model\n",
    "def reslicer(corpus):\n",
    "    final_test_n = 500 # can be adjusted\n",
    "    dev_test_n = 500 # can be adjusted\n",
    "    \n",
    "    test_corpus = corpus[:final_test_n] #reserve first 500 for the final test\n",
    "    print(\"Test Corpus Sample: \", test_corpus[0:3], \", Length: \", len(test_corpus))\n",
    "    \n",
    "    dev_set = corpus[final_test_n:] #create a copy of the dev_set to preserve the original test set before shuffling\n",
    "    random.shuffle(dev_set) #remix before re-slicing\n",
    "    \n",
    "    dev_test_corpus = dev_set[:dev_test_n]\n",
    "    print(\"Dev-Test Corpus Sample: \",dev_test_corpus[0:3], \", Length: \", len(dev_test_corpus)) #should have length 500\n",
    "    \n",
    "    train_corpus = dev_set[dev_test_n:]\n",
    "    print(\"Training Corpus Sample: \",train_corpus[0:3], \", Length: \", len(train_corpus)) #should be longer\n",
    "\n",
    "    return train_corpus, dev_test_corpus, test_corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Corpus Sample:  [('Niall', 'male'), ('Munroe', 'male'), ('Samuella', 'female')] , Length:  500\n",
      "Dev-Test Corpus Sample:  [('Letitia', 'female'), ('Kylen', 'female'), ('Judy', 'male')] , Length:  500\n",
      "Training Corpus Sample:  [('Theophyllus', 'male'), ('Hubert', 'male'), ('Nanice', 'female')] , Length:  6944\n"
     ]
    }
   ],
   "source": [
    "train_names, dev_names, test_names = reslicer(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Corpus Sample:  [('Niall', 'male'), ('Munroe', 'male'), ('Samuella', 'female')] , Length:  500\n",
      "Dev-Test Corpus Sample:  [('Greg', 'male'), ('Camille', 'female'), ('Frannie', 'female')] , Length:  500\n",
      "Training Corpus Sample:  [('Belita', 'female'), ('Marijo', 'female'), ('Gunvor', 'female')] , Length:  6944\n"
     ]
    }
   ],
   "source": [
    "#re-running the code will remix the training and dev-test sets, while leaving the original test names intact\n",
    "train_names, dev_names, test_names = reslicer(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function definitions to process and classify the data\n",
    "Because we will be changing the feature function each time, we can create a series of functions to process and classify the data to to minimize repeated code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to process the names through feature extractor\n",
    "def feature_ext(feature_func, corpus):\n",
    "    \n",
    "    #first, remix and reslice the data to ensure we are using a new mix of dev-test and training data each time\n",
    "    train_names, dev_names, test_names = reslicer(corpus)\n",
    "    \n",
    "    #then, extract features from the names slices\n",
    "    train_set = [(feature_func(n), gender) for (n, gender) in train_names]\n",
    "    devtest_set = [(feature_func(n), gender) for (n, gender) in dev_names]\n",
    "    test_set = [(feature_func(n), gender) for (n, gender) in test_names]\n",
    "    \n",
    "    return train_set, devtest_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(feature_func, corpus):\n",
    "    feature_func = feature_func #use feature function given as arg\n",
    "    corpus = corpus\n",
    "    \n",
    "    # Run the feature_ext function to create the necessary labeled feature sets\n",
    "    train_set, devtest_set, test_set = feature_ext(feature_func, corpus)\n",
    "    \n",
    "    # Train the naiveBayes classifier\n",
    "    classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "    # Test the accuracy of the classifier on the dev data--this is so we can evaluate errors and make tweaks\n",
    "    a = round(nltk.classify.accuracy(classifier, devtest_set), 4)*100\n",
    "    accuracy = f'{a:.2f}'\n",
    "    print(\"\\n\")\n",
    "    print(\"Model is %s percent accurate\" % accuracy)\n",
    "    print(\"\\n\")\n",
    "    # examine classifier to determine which last letter is most effective for\n",
    "    # distinguishing the name's gender\n",
    "    print(classifier.show_most_informative_features(10))\n",
    "    \n",
    "    def find_errors(dev_names, feature_func):\n",
    "        errors = {'name' : [], 'label' : [], 'guess' : [], 'features': [] }\n",
    "        for (name, label) in dev_names:\n",
    "            guess = classifier.classify(feature_func(name))\n",
    "            features = feature_func(name)\n",
    "            if guess != label:\n",
    "                errors['name'].append(name)\n",
    "                errors['label'].append(label)\n",
    "                errors['guess'].append(guess)\n",
    "                errors['features'].append(features)\n",
    "        errors = pd.DataFrame(errors)\n",
    "        print(\"\\nErrors\")\n",
    "        print(errors.sample(20))\n",
    "    \n",
    "    errors = find_errors(dev_names, feature_func)\n",
    "    \n",
    "    return errors\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on the last letter of the name\n",
    "\n",
    "Now that we have our functions set up, we can define some differnt feature extraction functions and test each one.\n",
    "\n",
    "First, we will test a model by examining only the last letter of each name. We will use ```nltk```'s built-in Naive Baysian Classifier to train the model based on this feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_letter(word): #first feature functiont to test\n",
    "    \n",
    "    return {\"last_letter\": word[-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Corpus Sample:  [('Niall', 'male'), ('Munroe', 'male'), ('Samuella', 'female')] , Length:  500\n",
      "Dev-Test Corpus Sample:  [('Penni', 'female'), ('Prissie', 'female'), ('Parker', 'male')] , Length:  500\n",
      "Training Corpus Sample:  [('Dani', 'female'), ('Essa', 'female'), ('Anne-Corinne', 'female')] , Length:  6944\n",
      "\n",
      "\n",
      "Model is 76.40 percent accurate\n",
      "\n",
      "\n",
      "Most Informative Features\n",
      "             last_letter = 'a'            female : male   =     41.1 : 1.0\n",
      "             last_letter = 'k'              male : female =     28.4 : 1.0\n",
      "             last_letter = 'f'              male : female =     26.6 : 1.0\n",
      "             last_letter = 'p'              male : female =     12.6 : 1.0\n",
      "             last_letter = 'v'              male : female =      9.9 : 1.0\n",
      "             last_letter = 'd'              male : female =      9.5 : 1.0\n",
      "             last_letter = 'o'              male : female =      8.7 : 1.0\n",
      "             last_letter = 'm'              male : female =      7.9 : 1.0\n",
      "             last_letter = 'r'              male : female =      6.7 : 1.0\n",
      "             last_letter = 'w'              male : female =      4.8 : 1.0\n",
      "None\n",
      "\n",
      "Errors\n",
      "         name   label   guess              features\n",
      "88      Janel  female    male  {'last_letter': 'l'}\n",
      "80       Bryn  female    male  {'last_letter': 'n'}\n",
      "37        Che    male  female  {'last_letter': 'e'}\n",
      "81     Meggan  female    male  {'last_letter': 'n'}\n",
      "67    Frankie    male  female  {'last_letter': 'e'}\n",
      "61   Katheryn  female    male  {'last_letter': 'n'}\n",
      "16        Sly    male  female  {'last_letter': 'y'}\n",
      "111      Adel  female    male  {'last_letter': 'l'}\n",
      "41     Bailey    male  female  {'last_letter': 'y'}\n",
      "38     Coleen  female    male  {'last_letter': 'n'}\n",
      "13      Karel  female    male  {'last_letter': 'l'}\n",
      "94    Anatoly    male  female  {'last_letter': 'y'}\n",
      "28       Yuri    male  female  {'last_letter': 'i'}\n",
      "97      Trace    male  female  {'last_letter': 'e'}\n",
      "102       Nan  female    male  {'last_letter': 'n'}\n",
      "3       Sarge    male  female  {'last_letter': 'e'}\n",
      "2       Heath    male  female  {'last_letter': 'h'}\n",
      "6     Demetre    male  female  {'last_letter': 'e'}\n",
      "39       Pepe    male  female  {'last_letter': 'e'}\n",
      "63       Cary    male  female  {'last_letter': 'y'}\n"
     ]
    }
   ],
   "source": [
    "test_model(last_letter, corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are interesting results! Ending in `a` is the *only* letter in the top ten that predicts female names instead of male names. \n",
    "\n",
    "Does this basic model work for our names? Let's write a short script to test our names and print a result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert Data Viz?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on the last 3 letters of the name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we try adding the last 3 letters as well as just the last letter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Corpus Sample:  [('Niall', 'male'), ('Munroe', 'male'), ('Samuella', 'female')] , Length:  500\n",
      "Dev-Test Corpus Sample:  [('Dennis', 'male'), ('Alf', 'male'), ('Salem', 'male')] , Length:  500\n",
      "Training Corpus Sample:  [('Selie', 'female'), ('Elihu', 'male'), ('Reagan', 'male')] , Length:  6944\n",
      "\n",
      "\n",
      "Model is 81.80 percent accurate\n",
      "\n",
      "\n",
      "Most Informative Features\n",
      "             last_letter = 'a'            female : male   =     40.8 : 1.0\n",
      "             last_letter = 'k'              male : female =     30.5 : 1.0\n",
      "             last_letter = 'f'              male : female =     26.4 : 1.0\n",
      "            last3letters = 'ita'          female : male   =     25.4 : 1.0\n",
      "            last3letters = 'ana'          female : male   =     23.7 : 1.0\n",
      "            last3letters = 'tta'          female : male   =     23.2 : 1.0\n",
      "            last3letters = 'nne'          female : male   =     19.1 : 1.0\n",
      "            last3letters = 'ard'            male : female =     18.6 : 1.0\n",
      "            last3letters = 'vin'            male : female =     17.9 : 1.0\n",
      "            last3letters = 'ert'            male : female =     16.9 : 1.0\n",
      "None\n",
      "\n",
      "Errors\n",
      "        name   label   guess                                     features\n",
      "11    Reggie    male  female  {'last_letter': 'e', 'last3letters': 'gie'}\n",
      "13      Pace    male  female  {'last_letter': 'e', 'last3letters': 'ace'}\n",
      "61    Easter  female    male  {'last_letter': 'r', 'last3letters': 'ter'}\n",
      "1      Aidan  female    male  {'last_letter': 'n', 'last3letters': 'dan'}\n",
      "32   Giavani    male  female  {'last_letter': 'i', 'last3letters': 'ani'}\n",
      "77     Nerty  female    male  {'last_letter': 'y', 'last3letters': 'rty'}\n",
      "54     Inger  female    male  {'last_letter': 'r', 'last3letters': 'ger'}\n",
      "79    Alison  female    male  {'last_letter': 'n', 'last3letters': 'son'}\n",
      "44    Jazmin  female    male  {'last_letter': 'n', 'last3letters': 'min'}\n",
      "69    Davide    male  female  {'last_letter': 'e', 'last3letters': 'ide'}\n",
      "33  Milicent  female    male  {'last_letter': 't', 'last3letters': 'ent'}\n",
      "55      Dani    male  female  {'last_letter': 'i', 'last3letters': 'ani'}\n",
      "15       Sal    male  female  {'last_letter': 'l', 'last3letters': 'Sal'}\n",
      "8     Donnie    male  female  {'last_letter': 'e', 'last3letters': 'nie'}\n",
      "62     Marlo  female    male  {'last_letter': 'o', 'last3letters': 'rlo'}\n",
      "80    Mikako  female    male  {'last_letter': 'o', 'last3letters': 'ako'}\n",
      "39    Hedvig  female    male  {'last_letter': 'g', 'last3letters': 'vig'}\n",
      "20      Yuri    male  female  {'last_letter': 'i', 'last3letters': 'uri'}\n",
      "56    Meggan  female    male  {'last_letter': 'n', 'last3letters': 'gan'}\n",
      "42   Michele    male  female  {'last_letter': 'e', 'last3letters': 'ele'}\n"
     ]
    }
   ],
   "source": [
    "def two_features(word):\n",
    "    return {\"last_letter\": word[-1], \"last3letters\": word[-3:]}  # feature set\n",
    "\n",
    "#note, we are automatically re-slicing the training/dev-test slices\n",
    "errors = test_model(two_features, corpus) #setting the result to errors will allow us to investigate further"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the last three letters increased our accuracy by about 5 percentage points! Let's see if we can learn anything from the remaining errors to improve our model further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maybe can cut this section -- or use for mor error analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ### Analysis of name parts\n",
    "   \n",
    "Next, let's take a look at whether the presence or absense of any letters or consecutive groups of letters can tell us anything about the names by doing an analysis.\n",
    "\n",
    "First, we create a function that returns all the combinations consecutive letters in a name, except the name itself. So, for example, in the name, \"Noah\", it returns the list:\n",
    "```['N', 'No', 'Noa', 'o', 'oa', 'oah', 'a', 'ah', 'h']```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'feature': 'N'}, {'feature': 'No'}, {'feature': 'Noa'}, {'feature': 'Noah'}, {'feature': 'o'}, {'feature': 'oa'}, {'feature': 'oah'}, {'feature': 'a'}, {'feature': 'ah'}, {'feature': 'h'}]\n"
     ]
    }
   ],
   "source": [
    "def name_parts(name):\n",
    "    i = 0\n",
    "    letters = ''\n",
    "    parts = []\n",
    "    ans = ''\n",
    "    for letter in name:\n",
    "        next_part = name[i:]\n",
    "        for letter in next_part:\n",
    "            letters += letter\n",
    "            parts.append({'feature':letters})\n",
    "            i+=0\n",
    "        letters=''\n",
    "        i += 1\n",
    "    return parts\n",
    "print(name_parts(\"Noah\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parts_set(name_set):\n",
    "    parts_set = []\n",
    "    for name, label in name_set:\n",
    "        features_list = name_parts(name)\n",
    "        #print(features_list)\n",
    "        parts_list = [(item, label) for item in features_list]\n",
    "        #print(parts_list)\n",
    "        parts_set += parts_list\n",
    "        #print(parts_set)\n",
    "    return parts_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set2 = parts_set(train_names)\n",
    "dev_set2 = parts_set(dev_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is 70 percent accurate\n",
      "\n",
      "Most Informative Features\n",
      "                 feature = 'tte'          female : male   =     37.9 : 1.0\n",
      "                 feature = 'rv'             male : female =     30.6 : 1.0\n",
      "                 feature = 'tta'          female : male   =     23.4 : 1.0\n",
      "                 feature = 'iss'          female : male   =     22.6 : 1.0\n",
      "                 feature = 'hu'             male : female =     22.0 : 1.0\n",
      "                 feature = 'ing'            male : female =     18.8 : 1.0\n",
      "                 feature = 'etta'         female : male   =     18.4 : 1.0\n",
      "                 feature = 'ton'            male : female =     17.4 : 1.0\n",
      "                 feature = 'Ros'          female : male   =     16.8 : 1.0\n",
      "                 feature = 'rw'             male : female =     16.6 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Train the naiveBayes classifier\n",
    "classifier2 = nltk.NaiveBayesClassifier.train(train_set2)\n",
    "\n",
    "accuracy = round(nltk.classify.accuracy(classifier2, dev_set2), 2)*100\n",
    "\n",
    "# Test the accuracy of the classifier on the test data\n",
    "print(\"Model is %d percent accurate\" % accuracy)\n",
    "print(\"\")\n",
    "\n",
    "# examine classifier to determine which feature is most effective for\n",
    "# distinguishing the name's gender\n",
    "print(classifier2.show_most_informative_features(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `sklearn`  \n",
    "\n",
    "From the site: https://blog.ayoungprogrammer.com/2016/04/determining-gender-of-name-with-80.html/    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the names corpus with gender assignment; each name is converted to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_names = ([(name.lower(), \"M\") for name in names.words(\"male.txt\")] +\n",
    "                 [(name.lower(), \"F\") for name in names.words(\"female.txt\")])\n",
    "\n",
    "my_data = np.asarray(labeled_names) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `sklearn`, we train a model on numbers associated with each letter in the name, where a=1, b=2, c=3, ... in this manner a model is created based on integer values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7219679633867276\n",
      "0.7292143401983219\n",
      "0.7315026697177727\n",
      "0.7257818459191457\n",
      "0.7265446224256293\n"
     ]
    }
   ],
   "source": [
    "def name_count(name):\n",
    "    arr = np.zeros(65)\n",
    "    for ind, x in enumerate(name):\n",
    "        arr[ord(x)-ord('a')] += 1\n",
    "    return arr\n",
    "\n",
    "name_map = np.vectorize(name_count, otypes=[np.ndarray])\n",
    "Xlist = name_map(np.asarray(list(zip(*my_data))[0],dtype=str))\n",
    "X = np.array(Xlist.tolist())\n",
    "y = [x[1] for x in my_data]\n",
    "\n",
    "for x in range(5):\n",
    "    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.33)\n",
    "    clf = RandomForestClassifier(n_estimators=100, min_samples_split=2)\n",
    "    clf.fit(Xtr, ytr)\n",
    "    print(np.mean(clf.predict(Xte) == yte))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7829900839054157\n",
      "0.7807017543859649\n",
      "0.7864225781845919\n",
      "0.7688787185354691\n",
      "0.7936689549961862\n"
     ]
    }
   ],
   "source": [
    "def name_count2(name):\n",
    "    arr = np.zeros(65+26)\n",
    "    for ind, x in enumerate(name):\n",
    "        arr[ord(x)-ord('a')] += 1\n",
    "        arr[ord(x)-ord('a')+26] += ind+1\n",
    "    return arr\n",
    "\n",
    "name_map2 = np.vectorize(name_count2, otypes=[np.ndarray])\n",
    "Xlist = name_map2(np.asarray(list(zip(*my_data))[0],dtype=str))\n",
    "X = np.array(Xlist.tolist())\n",
    "y = [x[1] for x in my_data]\n",
    "\n",
    "for x in range(5):\n",
    "    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.33)\n",
    "    clf = RandomForestClassifier(n_estimators=100, min_samples_split=2)\n",
    "    clf.fit(Xtr, ytr)\n",
    "    print(np.mean(clf.predict(Xte) == yte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7963386727688787\n",
      "0.7967200610221206\n",
      "0.7894736842105263\n",
      "0.7917620137299771\n",
      "0.7921434019832189\n"
     ]
    }
   ],
   "source": [
    "def name_count3(name):\n",
    "    arr = np.zeros(1800)\n",
    "    # Iterate each character\n",
    "    for ind, x in enumerate(name):\n",
    "        arr[ord(x)-ord('a')] += 1\n",
    "        arr[ord(x)-ord('a')+26] += ind+1\n",
    "    # Iterate every 2 characters\n",
    "    for x in range(len(name)-1):\n",
    "        ind = (ord(name[x])-ord('a'))*26 + (ord(name[x+1])-ord('a')) + 52\n",
    "        arr[ind] += 1\n",
    "    return arr\n",
    "\n",
    "name_map3 = np.vectorize(name_count3, otypes=[np.ndarray])\n",
    "Xlist = name_map3(np.asarray(list(zip(*my_data))[0],dtype=str))\n",
    "X = np.array(Xlist.tolist())\n",
    "y = [x[1] for x in my_data]\n",
    "\n",
    "for x in range(5):\n",
    "    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.33)\n",
    "    clf = RandomForestClassifier(n_estimators=100, min_samples_split=2)\n",
    "    clf.fit(Xtr, ytr)\n",
    "    print(np.mean(clf.predict(Xte) == yte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8180778032036613\n",
      "0.8188405797101449\n",
      "0.8096872616323417\n",
      "0.8032036613272311\n",
      "0.8081617086193745\n"
     ]
    }
   ],
   "source": [
    "def name_count4(name):\n",
    "    arr = np.zeros(1800)\n",
    "    # Iterate each character\n",
    "    for ind, x in enumerate(name):\n",
    "        arr[ord(x)-ord('a')] += 1\n",
    "        arr[ord(x)-ord('a')+26] += ind+1\n",
    "    # Iterate every 2 characters\n",
    "    for x in range(len(name)-1):\n",
    "        ind = (ord(name[x])-ord('a'))*26 + (ord(name[x+1])-ord('a')) + 52\n",
    "        arr[ind] += 1\n",
    "    # Last character\n",
    "    arr[-3] = ord(name[-1])-ord('a')+1\n",
    "    # Second Last character\n",
    "    arr[-2] = ord(name[-2])-ord('a')+1\n",
    "    # Length of name\n",
    "    arr[-1] = len(name)\n",
    "    return arr\n",
    "\n",
    "name_map4 = np.vectorize(name_count4, otypes=[np.ndarray])\n",
    "Xlist = name_map4(np.asarray(list(zip(*my_data))[0],dtype=str))\n",
    "X = np.array(Xlist.tolist())\n",
    "y = [x[1] for x in my_data]\n",
    "\n",
    "for x in range(5):\n",
    "    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.33)\n",
    "    clf = RandomForestClassifier(n_estimators=100, min_samples_split=2)\n",
    "    clf.fit(Xtr, ytr)\n",
    "    print(np.mean(clf.predict(Xte) == yte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1797   26 1798   40   30   34    0   43   29    8]\n",
      "0.8081617086193745\n",
      "[1797   26 1798   40   30    0   34   43   22   29]\n",
      "0.8119755911517925\n",
      "[1797   26 1798   40    0   30   34   43 1799    8]\n",
      "0.8005339435545386\n",
      "[1797   26 1798   40   30    0   34   43   29 1799]\n",
      "0.8012967200610221\n",
      "[1797   26 1798   40    0   30   34   43   29 1799]\n",
      "0.8154080854309688\n"
     ]
    }
   ],
   "source": [
    "def name_count7(name):\n",
    "    arr = np.zeros(1800)\n",
    "    # Iterate each character\n",
    "    for ind, x in enumerate(name):\n",
    "        arr[ord(x)-ord('a')] += 1\n",
    "        arr[ord(x)-ord('a')+26] += ind+1\n",
    "    # Iterate every 2 characters\n",
    "    for x in range(len(name)-1):\n",
    "        ind = (ord(name[x])-ord('a'))*26 + (ord(name[x+1])-ord('a')) + 52\n",
    "        arr[ind] += 1\n",
    "    # Last character\n",
    "    arr[-3] = ord(name[-1])-ord('a')+1\n",
    "    # Second Last character\n",
    "    arr[-2] = ord(name[-2])-ord('a')+1\n",
    "    # Length of name\n",
    "    arr[-1] = len(name)\n",
    "    return arr\n",
    "\n",
    "name_map7 = np.vectorize(name_count7, otypes=[np.ndarray])\n",
    "Xlist = name_map7(np.asarray(list(zip(*my_data))[0],dtype=str))\n",
    "X = np.array(Xlist.tolist())\n",
    "y = [x[1] for x in my_data]\n",
    "\n",
    "for x in range(5):\n",
    "    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.33)\n",
    "    clf = RandomForestClassifier(n_estimators=150, min_samples_split=20)\n",
    "    clf.fit(Xtr, ytr)\n",
    "    print(clf.feature_importances_.argsort()[-10:][::-1])\n",
    "    print(np.mean(clf.predict(Xte) == yte))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code trains a model based on the last letter of the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.761632341723875\n",
      "0.7715484363081617\n",
      "0.7528604118993135\n",
      "0.7570556826849733\n",
      "0.7589626239511823\n"
     ]
    }
   ],
   "source": [
    "def name_count8(name):\n",
    "    arr = np.zeros(1)\n",
    "    arr[0] = ord(name[-1])-ord('a')+1\n",
    "    return arr\n",
    "\n",
    "name_map8 = np.vectorize(name_count8, otypes=[np.ndarray])\n",
    "Xlist = name_map8(np.asarray(list(zip(*my_data))[0],dtype=str))\n",
    "X = np.array(Xlist.tolist())\n",
    "y = [x[1] for x in my_data]\n",
    "\n",
    "for x in range(5):\n",
    "    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.33)\n",
    "    clf = RandomForestClassifier(n_estimators=150, min_samples_split=20)\n",
    "    clf.fit(Xtr, ytr)\n",
    "    print(np.mean(clf.predict(Xte) == yte))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code trains a model based on the last three letters of the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7890922959572845\n",
      "0.7913806254767353\n",
      "0.8012967200610221\n",
      "0.7940503432494279\n",
      "0.8032036613272311\n"
     ]
    }
   ],
   "source": [
    "def name_count9(name):\n",
    "    arr = np.zeros(3)\n",
    "    arr[0] = ord(name[-1])-ord('a')+1\n",
    "    arr[1] = ord(name[-2])-ord('a')+1\n",
    "    for ind, x in enumerate(name):\n",
    "        if len(name)>=3:\n",
    "            arr[2] = ord(name[-3])-ord('a')+1\n",
    "    \n",
    "    return arr\n",
    "\n",
    "name_map9 = np.vectorize(name_count9, otypes=[np.ndarray])\n",
    "Xlist = name_map9(np.asarray(list(zip(*my_data))[0],dtype=str))\n",
    "X = np.array(Xlist.tolist())\n",
    "y = [x[1] for x in my_data]\n",
    "\n",
    "for x in range(5):\n",
    "    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.33)\n",
    "    clf = RandomForestClassifier(n_estimators=150, min_samples_split=20)\n",
    "    clf.fit(Xtr, ytr)\n",
    "    print(np.mean(clf.predict(Xte) == yte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7784134248665141\n",
      "0.7738367658276125\n",
      "0.7734553775743707\n",
      "0.7837528604118993\n",
      "0.7738367658276125\n"
     ]
    }
   ],
   "source": [
    "def name_count10(name):\n",
    "    arr = np.zeros(3)\n",
    "    arr[0] = ord(name[-1])-ord('a')+1\n",
    "    arr[1] = ord(name[-2])-ord('a')+1\n",
    "    # Order of a's\n",
    "    for ind, x in enumerate(name):\n",
    "        if x == 'a':\n",
    "            arr[2] += ind+1\n",
    "    \n",
    "    return arr\n",
    "\n",
    "name_map10 = np.vectorize(name_count10, otypes=[np.ndarray])\n",
    "Xlist = name_map10(np.asarray(list(zip(*my_data))[0],dtype=str))\n",
    "X = np.array(Xlist.tolist())\n",
    "y = [x[1] for x in my_data]\n",
    "\n",
    "for x in range(5):\n",
    "    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.33)\n",
    "    clf = RandomForestClassifier(n_estimators=150, min_samples_split=20)\n",
    "    clf.fit(Xtr, ytr)\n",
    "    print(np.mean(clf.predict(Xte) == yte))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reid M M\n",
      "galina F F\n",
      "bishop M M\n",
      "channa F F\n",
      "uta F F\n",
      "tracy M M\n",
      "gillian F M\n",
      "cindi F F\n",
      "eustacia F F\n",
      "raleigh M M\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.choice(np.arange(len(Xlist)), 10, replace=False)\n",
    "Xname = [x[0] for x in my_data]\n",
    "xs = [Xname[x] for x in idx]\n",
    "ys = [y[x] for x in idx]\n",
    "pred = clf.predict(X[idx])\n",
    "\n",
    "for a,b, p in zip(xs,ys, pred):\n",
    "    print(a,b, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18.  9. 13.]\n",
      "aamir\n",
      "[14. 15. 18.]\n",
      "aaron\n",
      "[25.  5.  2.]\n",
      "abbey\n",
      "[5. 9. 2.]\n",
      "abbie\n",
      "[20. 15.  2.]\n",
      "abbot\n"
     ]
    }
   ],
   "source": [
    "for x in range(5): \n",
    "    print(X[x])\n",
    "    print(Xname[x])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
